model_id,url,cotaniner,license,gated,private,configuration,likes,likes30d,downloads
mistralai/Mixtral-8x7B-Instruct-v0.1,https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'num_gpus': 2, 'quantization_type': None}",3403,482,984664
bigcode/starcoder2-15b,https://huggingface.co/bigcode/starcoder2-15b,PyTorch TGI GPU,bigcode-openrail-m,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'bigcode/starcoder2-15b', 'num_gpus': 2, 'quantization_type': None}",461,461,112526
meta-llama/Llama-2-7b-chat-hf,https://huggingface.co/meta-llama/Llama-2-7b-chat-hf,PyTorch TGI GPU,N/A,True,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'meta-llama/Llama-2-7b-chat-hf', 'num_gpus': 1, 'quantization_type': None}",3114,349,1333672
mistralai/Mistral-7B-Instruct-v0.2,https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'mistralai/Mistral-7B-Instruct-v0.2', 'num_gpus': 1, 'quantization_type': None}",1209,315,1679525
NousResearch/Genstruct-7B,https://huggingface.co/NousResearch/Genstruct-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 18, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'NousResearch/Genstruct-7B', 'num_gpus': 1, 'quantization_type': None}",311,311,2601
NousResearch/Hermes-2-Pro-Mistral-7B,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'NousResearch/Hermes-2-Pro-Mistral-7B', 'num_gpus': 1, 'quantization_type': None}",270,270,9310
BioMistral/BioMistral-7B,https://huggingface.co/BioMistral/BioMistral-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'BioMistral/BioMistral-7B', 'num_gpus': 1, 'quantization_type': None}",302,199,17608
microsoft/phi-2,https://huggingface.co/microsoft/phi-2,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 8, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'microsoft/phi-2', 'num_gpus': 1, 'quantization_type': None}",2957,198,652581
mistralai/Mistral-7B-v0.1,https://huggingface.co/mistralai/Mistral-7B-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'mistralai/Mistral-7B-v0.1', 'num_gpus': 1, 'quantization_type': None}",2982,191,2604186
01-ai/Yi-9B,https://huggingface.co/01-ai/Yi-9B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 4096, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': '01-ai/Yi-9B', 'num_gpus': 1, 'quantization_type': None}",167,167,4928
NousResearch/Nous-Hermes-2-Mistral-7B-DPO,https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'NousResearch/Nous-Hermes-2-Mistral-7B-DPO', 'num_gpus': 1, 'quantization_type': None}",132,132,20218
CohereForAI/aya-101,https://huggingface.co/CohereForAI/aya-101,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 30, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'CohereForAI/aya-101', 'num_gpus': 2, 'quantization_type': None}",473,125,16772
bigcode/starcoder2-7b,https://huggingface.co/bigcode/starcoder2-7b,PyTorch TGI GPU,bigcode-openrail-m,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'bigcode/starcoder2-7b', 'num_gpus': 1, 'quantization_type': None}",121,121,14193
meta-llama/Llama-2-7b-hf,https://huggingface.co/meta-llama/Llama-2-7b-hf,PyTorch TGI GPU,N/A,True,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'meta-llama/Llama-2-7b-hf', 'num_gpus': 1, 'quantization_type': None}",1218,117,873889
mistralai/Mixtral-8x7B-v0.1,https://huggingface.co/mistralai/Mixtral-8x7B-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'mistralai/Mixtral-8x7B-v0.1', 'num_gpus': 2, 'quantization_type': None}",1426,117,167391
abacusai/Smaug-72B-v0.1,https://huggingface.co/abacusai/Smaug-72B-v0.1,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 318, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 32768, 'max_input_length': 4000, 'max_total_tokens': 4096, 'model_id': 'abacusai/Smaug-72B-v0.1', 'num_gpus': 4, 'quantization_type': None}",418,111,29888
m-a-p/OpenCodeInterpreter-DS-6.7B,https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-6.7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'm-a-p/OpenCodeInterpreter-DS-6.7B', 'num_gpus': 1, 'quantization_type': None}",103,103,4548
HuggingFaceH4/zephyr-7b-gemma-v0.1,https://huggingface.co/HuggingFaceH4/zephyr-7b-gemma-v0.1,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 20, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'HuggingFaceH4/zephyr-7b-gemma-v0.1', 'num_gpus': 1, 'quantization_type': None}",101,101,16699
fireworks-ai/firefunction-v1,https://huggingface.co/fireworks-ai/firefunction-v1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'fireworks-ai/firefunction-v1', 'num_gpus': 2, 'quantization_type': None}",100,100,2071
HuggingFaceTB/cosmo-1b,https://huggingface.co/HuggingFaceTB/cosmo-1b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 14, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'HuggingFaceTB/cosmo-1b', 'num_gpus': 1, 'quantization_type': None}",96,96,8343
NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO,https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO', 'num_gpus': 2, 'quantization_type': None}",301,93,32686
bigcode/starcoder2-3b,https://huggingface.co/bigcode/starcoder2-3b,PyTorch TGI GPU,bigcode-openrail-m,False,False,"{'estimated_memory_in_gigabytes': 14, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'bigcode/starcoder2-3b', 'num_gpus': 1, 'quantization_type': None}",92,92,21267
m-a-p/ChatMusician,https://huggingface.co/m-a-p/ChatMusician,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'm-a-p/ChatMusician', 'num_gpus': 1, 'quantization_type': None}",87,87,1437
ibm/merlinite-7b,https://huggingface.co/ibm/merlinite-7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ibm/merlinite-7b', 'num_gpus': 1, 'quantization_type': None}",84,84,17583
bigscience/bloom,https://huggingface.co/bigscience/bloom,PyTorch TGI GPU,bigscience-bloom-rail-1.0,False,False,"{'estimated_memory_in_gigabytes': 411, 'gcp_instance': 'a2-ultragpu-8g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'bigscience/bloom', 'num_gpus': 8, 'quantization_type': None}",4475,83,10834
HuggingFaceH4/zephyr-7b-beta,https://huggingface.co/HuggingFaceH4/zephyr-7b-beta,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'HuggingFaceH4/zephyr-7b-beta', 'num_gpus': 1, 'quantization_type': None}",1373,81,689452
gorilla-llm/gorilla-openfunctions-v2,https://huggingface.co/gorilla-llm/gorilla-openfunctions-v2,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'gorilla-llm/gorilla-openfunctions-v2', 'num_gpus': 1, 'quantization_type': None}",80,80,13205
abacaj/phi-2-super,https://huggingface.co/abacaj/phi-2-super,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 8, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'abacaj/phi-2-super', 'num_gpus': 1, 'quantization_type': None}",76,76,5687
openai-community/gpt2,https://huggingface.co/openai-community/gpt2,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 1, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'openai-community/gpt2', 'num_gpus': 1, 'quantization_type': None}",1746,73,7695267
Qwen/Qwen1.5-72B-Chat,https://huggingface.co/Qwen/Qwen1.5-72B-Chat,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 242, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'Qwen/Qwen1.5-72B-Chat', 'num_gpus': 4, 'quantization_type': None}",156,73,32324
teknium/OpenHermes-2.5-Mistral-7B,https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'teknium/OpenHermes-2.5-Mistral-7B', 'num_gpus': 1, 'quantization_type': None}",714,72,151572
meta-llama/Llama-2-70b-chat-hf,https://huggingface.co/meta-llama/Llama-2-70b-chat-hf,PyTorch TGI GPU,N/A,True,False,"{'estimated_memory_in_gigabytes': 159, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'meta-llama/Llama-2-70b-chat-hf', 'num_gpus': 2, 'quantization_type': None}",2035,71,218887
mlabonne/AlphaMonarch-7B,https://huggingface.co/mlabonne/AlphaMonarch-7B,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'mlabonne/AlphaMonarch-7B', 'num_gpus': 1, 'quantization_type': None}",115,68,5106
HuggingFaceH4/starchat2-15b-v0.1,https://huggingface.co/HuggingFaceH4/starchat2-15b-v0.1,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 39, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'HuggingFaceH4/starchat2-15b-v0.1', 'num_gpus': 2, 'quantization_type': None}",67,67,666
deepseek-ai/deepseek-coder-33b-instruct,https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 78, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'deepseek-ai/deepseek-coder-33b-instruct', 'num_gpus': 1, 'quantization_type': None}",333,66,27166
ibm/labradorite-13b,https://huggingface.co/ibm/labradorite-13b,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ibm/labradorite-13b', 'num_gpus': 2, 'quantization_type': None}",66,66,3670
bigcode/starcoder,https://huggingface.co/bigcode/starcoder,PyTorch TGI GPU,bigcode-openrail-m,True,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'bigcode/starcoder', 'num_gpus': 2, 'quantization_type': None}",2677,64,16330
01-ai/Yi-34B-200K,https://huggingface.co/01-ai/Yi-34B-200K,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 122, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': '01-ai/Yi-34B-200K', 'num_gpus': 2, 'quantization_type': None}",287,64,12353
openchat/openchat-3.5-0106,https://huggingface.co/openchat/openchat-3.5-0106,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'openchat/openchat-3.5-0106', 'num_gpus': 1, 'quantization_type': None}",249,62,58383
TencentARC/Mistral_Pro_8B_v0.1,https://huggingface.co/TencentARC/Mistral_Pro_8B_v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'TencentARC/Mistral_Pro_8B_v0.1', 'num_gpus': 1, 'quantization_type': None}",61,61,4484
yam-peleg/Experiment26-7B,https://huggingface.co/yam-peleg/Experiment26-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'yam-peleg/Experiment26-7B', 'num_gpus': 1, 'quantization_type': None}",60,60,5509
abacusai/Liberated-Qwen1.5-72B,https://huggingface.co/abacusai/Liberated-Qwen1.5-72B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 242, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'abacusai/Liberated-Qwen1.5-72B', 'num_gpus': 4, 'quantization_type': None}",60,60,2461
georgesung/llama2_7b_chat_uncensored,https://huggingface.co/georgesung/llama2_7b_chat_uncensored,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'georgesung/llama2_7b_chat_uncensored', 'num_gpus': 1, 'quantization_type': None}",246,57,4918
cognitivecomputations/dolphin-2.5-mixtral-8x7b,https://huggingface.co/cognitivecomputations/dolphin-2.5-mixtral-8x7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'cognitivecomputations/dolphin-2.5-mixtral-8x7b', 'num_gpus': 2, 'quantization_type': None}",1082,57,171243
m-a-p/OpenCodeInterpreter-DS-33B,https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-33B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 78, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'm-a-p/OpenCodeInterpreter-DS-33B', 'num_gpus': 1, 'quantization_type': None}",57,57,675
BatsResearch/bonito-v1,https://huggingface.co/BatsResearch/bonito-v1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'BatsResearch/bonito-v1', 'num_gpus': 1, 'quantization_type': None}",57,57,1251
Phind/Phind-CodeLlama-34B-v2,https://huggingface.co/Phind/Phind-CodeLlama-34B-v2,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'Phind/Phind-CodeLlama-34B-v2', 'num_gpus': 1, 'quantization_type': None}",744,56,22812
TinyLlama/TinyLlama-1.1B-Chat-v1.0,https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 4, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0', 'num_gpus': 1, 'quantization_type': None}",855,56,254212
mistralai/Mistral-7B-Instruct-v0.1,https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'mistralai/Mistral-7B-Instruct-v0.1', 'num_gpus': 1, 'quantization_type': None}",1367,51,674883
01-ai/Yi-9B-200K,https://huggingface.co/01-ai/Yi-9B-200K,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 34, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': '01-ai/Yi-9B-200K', 'num_gpus': 2, 'quantization_type': None}",51,51,641
meta-llama/Llama-2-13b-chat-hf,https://huggingface.co/meta-llama/Llama-2-13b-chat-hf,PyTorch TGI GPU,N/A,True,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'meta-llama/Llama-2-13b-chat-hf', 'num_gpus': 2, 'quantization_type': None}",898,49,511653
Qwen/Qwen1.5-7B-Chat,https://huggingface.co/Qwen/Qwen1.5-7B-Chat,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Qwen/Qwen1.5-7B-Chat', 'num_gpus': 1, 'quantization_type': None}",91,48,58928
FuseAI/FuseChat-7B-VaRM,https://huggingface.co/FuseAI/FuseChat-7B-VaRM,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'FuseAI/FuseChat-7B-VaRM', 'num_gpus': 1, 'quantization_type': None}",47,47,2411
cognitivecomputations/dolphincoder-starcoder2-15b,https://huggingface.co/cognitivecomputations/dolphincoder-starcoder2-15b,PyTorch TGI GPU,bigcode-openrail-m,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/dolphincoder-starcoder2-15b', 'num_gpus': 2, 'quantization_type': None}",47,47,2173
sambanovasystems/SambaLingo-Russian-Chat,https://huggingface.co/sambanovasystems/SambaLingo-Russian-Chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Russian-Chat', 'num_gpus': 1, 'quantization_type': None}",46,46,569
WhiteRabbitNeo/WhiteRabbitNeo-13B-v1,https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-13B-v1,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 39, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'WhiteRabbitNeo/WhiteRabbitNeo-13B-v1', 'num_gpus': 2, 'quantization_type': None}",336,45,2075
AetherResearch/Cerebrum-1.0-7b,https://huggingface.co/AetherResearch/Cerebrum-1.0-7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'AetherResearch/Cerebrum-1.0-7b', 'num_gpus': 1, 'quantization_type': None}",44,44,871
deepseek-ai/deepseek-coder-6.7b-instruct,https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'deepseek-ai/deepseek-coder-6.7b-instruct', 'num_gpus': 1, 'quantization_type': None}",243,39,32598
sambanovasystems/SambaLingo-Arabic-Chat,https://huggingface.co/sambanovasystems/SambaLingo-Arabic-Chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Arabic-Chat', 'num_gpus': 1, 'quantization_type': None}",39,39,799
sambanovasystems/SambaLingo-Turkish-Chat,https://huggingface.co/sambanovasystems/SambaLingo-Turkish-Chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Turkish-Chat', 'num_gpus': 1, 'quantization_type': None}",39,39,1192
intfloat/e5-mistral-7b-instruct,https://huggingface.co/intfloat/e5-mistral-7b-instruct,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'intfloat/e5-mistral-7b-instruct', 'num_gpus': 1, 'quantization_type': None}",350,38,92056
Sao10K/Fimbulvetr-11B-v2,https://huggingface.co/Sao10K/Fimbulvetr-11B-v2,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Sao10K/Fimbulvetr-11B-v2', 'num_gpus': 2, 'quantization_type': None}",54,37,3052
Weyaxi/Einstein-v4-7B,https://huggingface.co/Weyaxi/Einstein-v4-7B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Weyaxi/Einstein-v4-7B', 'num_gpus': 1, 'quantization_type': None}",37,37,2428
01-ai/Yi-34B-Chat,https://huggingface.co/01-ai/Yi-34B-Chat,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': '01-ai/Yi-34B-Chat', 'num_gpus': 1, 'quantization_type': None}",297,36,23143
Qwen/Qwen1.5-0.5B,https://huggingface.co/Qwen/Qwen1.5-0.5B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'Qwen/Qwen1.5-0.5B', 'num_gpus': 1, 'quantization_type': None}",76,36,71918
wolfram/miquliz-120b-v2.0,https://huggingface.co/wolfram/miquliz-120b-v2.0,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 318, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'wolfram/miquliz-120b-v2.0', 'num_gpus': 4, 'quantization_type': None}",64,35,3878
sambanovasystems/SambaLingo-Arabic-Base,https://huggingface.co/sambanovasystems/SambaLingo-Arabic-Base,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Arabic-Base', 'num_gpus': 1, 'quantization_type': None}",35,35,90
sambanovasystems/SambaLingo-Turkish-Base,https://huggingface.co/sambanovasystems/SambaLingo-Turkish-Base,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Turkish-Base', 'num_gpus': 1, 'quantization_type': None}",35,35,102
AetherResearch/Cerebrum-1.0-8x7b,https://huggingface.co/AetherResearch/Cerebrum-1.0-8x7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'AetherResearch/Cerebrum-1.0-8x7b', 'num_gpus': 2, 'quantization_type': None}",35,35,143
Nexusflow/Starling-LM-7B-beta,https://huggingface.co/Nexusflow/Starling-LM-7B-beta,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Nexusflow/Starling-LM-7B-beta', 'num_gpus': 1, 'quantization_type': None}",35,35,122
berkeley-nest/Starling-LM-7B-alpha,https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'berkeley-nest/Starling-LM-7B-alpha', 'num_gpus': 1, 'quantization_type': None}",496,34,77538
roborovski/superprompt-v1,https://huggingface.co/roborovski/superprompt-v1,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'berkeley-nest/Starling-LM-7B-alpha', 'num_gpus': 1, 'quantization_type': None}",34,34,8777
sambanovasystems/SambaLingo-Hungarian-Chat,https://huggingface.co/sambanovasystems/SambaLingo-Hungarian-Chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Hungarian-Chat', 'num_gpus': 1, 'quantization_type': None}",34,34,497
google/flan-t5-large,https://huggingface.co/google/flan-t5-large,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Hungarian-Chat', 'num_gpus': 1, 'quantization_type': None}",436,33,464456
openchat/openchat-3.5-0106-gemma,https://huggingface.co/openchat/openchat-3.5-0106-gemma,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'openchat/openchat-3.5-0106-gemma', 'num_gpus': 1, 'quantization_type': None}",33,33,3406
openchat/openchat_3.5,https://huggingface.co/openchat/openchat_3.5,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'openchat/openchat_3.5', 'num_gpus': 1, 'quantization_type': None}",1068,32,32216
01-ai/Yi-34B,https://huggingface.co/01-ai/Yi-34B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': '01-ai/Yi-34B', 'num_gpus': 1, 'quantization_type': None}",1211,32,13609
upstage/SOLAR-10.7B-Instruct-v1.0,https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'num_gpus': 2, 'quantization_type': None}",539,32,153109
WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a,https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a', 'num_gpus': 1, 'quantization_type': None}",32,32,312
l3utterfly/mistral-7b-v0.1-layla-v4,https://huggingface.co/l3utterfly/mistral-7b-v0.1-layla-v4,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'l3utterfly/mistral-7b-v0.1-layla-v4', 'num_gpus': 1, 'quantization_type': None}",32,32,2132
abacusai/bigstral-12b-32k,https://huggingface.co/abacusai/bigstral-12b-32k,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 36, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'abacusai/bigstral-12b-32k', 'num_gpus': 2, 'quantization_type': None}",32,32,2762
yam-peleg/Hebrew-Gemma-11B,https://huggingface.co/yam-peleg/Hebrew-Gemma-11B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 45, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'yam-peleg/Hebrew-Gemma-11B', 'num_gpus': 2, 'quantization_type': None}",32,32,724
Equall/Saul-Instruct-v1,https://huggingface.co/Equall/Saul-Instruct-v1,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Equall/Saul-Instruct-v1', 'num_gpus': 1, 'quantization_type': None}",31,31,2167
sambanovasystems/SambaLingo-Bulgarian-Chat,https://huggingface.co/sambanovasystems/SambaLingo-Bulgarian-Chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Bulgarian-Chat', 'num_gpus': 1, 'quantization_type': None}",31,31,51
sambanovasystems/SambaLingo-Japanese-Chat,https://huggingface.co/sambanovasystems/SambaLingo-Japanese-Chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Japanese-Chat', 'num_gpus': 1, 'quantization_type': None}",31,31,117
sambanovasystems/SambaLingo-Thai-Chat,https://huggingface.co/sambanovasystems/SambaLingo-Thai-Chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Thai-Chat', 'num_gpus': 1, 'quantization_type': None}",31,31,1881
sambanovasystems/SambaLingo-Hungarian-Base,https://huggingface.co/sambanovasystems/SambaLingo-Hungarian-Base,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Hungarian-Base', 'num_gpus': 1, 'quantization_type': None}",30,30,831
sambanovasystems/SambaLingo-Russian-Base,https://huggingface.co/sambanovasystems/SambaLingo-Russian-Base,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Russian-Base', 'num_gpus': 1, 'quantization_type': None}",30,30,322
google/flan-t5-base,https://huggingface.co/google/flan-t5-base,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Russian-Base', 'num_gpus': 1, 'quantization_type': None}",604,29,1682178
HuggingFaceH4/mistral-7b-grok,https://huggingface.co/HuggingFaceH4/mistral-7b-grok,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 18, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'HuggingFaceH4/mistral-7b-grok', 'num_gpus': 1, 'quantization_type': None}",32,29,123
sambanovasystems/SambaLingo-Thai-Base,https://huggingface.co/sambanovasystems/SambaLingo-Thai-Base,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Thai-Base', 'num_gpus': 1, 'quantization_type': None}",29,29,766
Qwen/Qwen1.5-14B-Chat,https://huggingface.co/Qwen/Qwen1.5-14B-Chat,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'Qwen/Qwen1.5-14B-Chat', 'num_gpus': 2, 'quantization_type': None}",59,28,27620
MBZUAI/MobiLlama-05B,https://huggingface.co/MBZUAI/MobiLlama-05B,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'MBZUAI/MobiLlama-05B', 'num_gpus': 1, 'quantization_type': None}",28,28,6403
sambanovasystems/SambaLingo-Slovenian-Chat,https://huggingface.co/sambanovasystems/SambaLingo-Slovenian-Chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Slovenian-Chat', 'num_gpus': 1, 'quantization_type': None}",28,28,128
sambanovasystems/SambaLingo-Serbian-Chat,https://huggingface.co/sambanovasystems/SambaLingo-Serbian-Chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Serbian-Chat', 'num_gpus': 1, 'quantization_type': None}",28,28,33
google/flan-t5-xxl,https://huggingface.co/google/flan-t5-xxl,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/SambaLingo-Serbian-Chat', 'num_gpus': 1, 'quantization_type': None}",1088,27,211055
meta-llama/Llama-2-70b-hf,https://huggingface.co/meta-llama/Llama-2-70b-hf,PyTorch TGI GPU,N/A,True,False,"{'estimated_memory_in_gigabytes': 159, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'meta-llama/Llama-2-70b-hf', 'num_gpus': 2, 'quantization_type': None}",775,27,77573
PipableAI/pip-sql-1.3b,https://huggingface.co/PipableAI/pip-sql-1.3b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'PipableAI/pip-sql-1.3b', 'num_gpus': 1, 'quantization_type': None}",60,27,3086
sambanovasystems/SambaLingo-Serbian-Base,https://huggingface.co/sambanovasystems/SambaLingo-Serbian-Base,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Serbian-Base', 'num_gpus': 1, 'quantization_type': None}",27,27,46
NousResearch/Nous-Hermes-2-Yi-34B,https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'NousResearch/Nous-Hermes-2-Yi-34B', 'num_gpus': 1, 'quantization_type': None}",202,26,8091
sambanovasystems/SambaLingo-Bulgarian-Base,https://huggingface.co/sambanovasystems/SambaLingo-Bulgarian-Base,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Bulgarian-Base', 'num_gpus': 1, 'quantization_type': None}",26,26,48
sophosympatheia/Midnight-Miqu-70B-v1.0,https://huggingface.co/sophosympatheia/Midnight-Miqu-70B-v1.0,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 158, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'sophosympatheia/Midnight-Miqu-70B-v1.0', 'num_gpus': 2, 'quantization_type': None}",26,26,2870
beomi/gemma-ko-7b,https://huggingface.co/beomi/gemma-ko-7b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'beomi/gemma-ko-7b', 'num_gpus': 1, 'quantization_type': None}",26,26,8054
microsoft/phi-1_5,https://huggingface.co/microsoft/phi-1_5,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 4, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'microsoft/phi-1_5', 'num_gpus': 1, 'quantization_type': None}",1237,25,70784
codellama/CodeLlama-70b-hf,https://huggingface.co/codellama/CodeLlama-70b-hf,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 159, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'codellama/CodeLlama-70b-hf', 'num_gpus': 2, 'quantization_type': None}",289,25,6732
sambanovasystems/SambaLingo-Japanese-Base,https://huggingface.co/sambanovasystems/SambaLingo-Japanese-Base,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Japanese-Base', 'num_gpus': 1, 'quantization_type': None}",25,25,66
sambanovasystems/SambaLingo-Slovenian-Base,https://huggingface.co/sambanovasystems/SambaLingo-Slovenian-Base,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sambanovasystems/SambaLingo-Slovenian-Base', 'num_gpus': 1, 'quantization_type': None}",25,25,47
OPI-PG/Qra-13b,https://huggingface.co/OPI-PG/Qra-13b,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'OPI-PG/Qra-13b', 'num_gpus': 2, 'quantization_type': None}",25,25,9365
lmsys/vicuna-7b-v1.5,https://huggingface.co/lmsys/vicuna-7b-v1.5,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'lmsys/vicuna-7b-v1.5', 'num_gpus': 1, 'quantization_type': None}",193,24,599581
Open-Orca/Mistral-7B-OpenOrca,https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Open-Orca/Mistral-7B-OpenOrca', 'num_gpus': 1, 'quantization_type': None}",624,24,155902
snorkelai/Snorkel-Mistral-PairRM-DPO,https://huggingface.co/snorkelai/Snorkel-Mistral-PairRM-DPO,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 18, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'snorkelai/Snorkel-Mistral-PairRM-DPO', 'num_gpus': 1, 'quantization_type': None}",93,24,3910
tiiuae/falcon-7b,https://huggingface.co/tiiuae/falcon-7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 18, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'tiiuae/falcon-7b', 'num_gpus': 1, 'quantization_type': None}",1013,23,175073
upstage/SOLAR-10.7B-v1.0,https://huggingface.co/upstage/SOLAR-10.7B-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'upstage/SOLAR-10.7B-v1.0', 'num_gpus': 2, 'quantization_type': None}",208,23,23179
senseable/WestLake-7B-v2,https://huggingface.co/senseable/WestLake-7B-v2,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'upstage/SOLAR-10.7B-v1.0', 'num_gpus': 2, 'quantization_type': None}",75,23,6710
152334H/miqu-1-70b-sf,https://huggingface.co/152334H/miqu-1-70b-sf,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 158, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': '152334H/miqu-1-70b-sf', 'num_gpus': 2, 'quantization_type': None}",201,23,17977
CausalLM/34b-beta,https://huggingface.co/CausalLM/34b-beta,PyTorch TGI GPU,gpl-3.0,False,False,"{'estimated_memory_in_gigabytes': 122, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'CausalLM/34b-beta', 'num_gpus': 2, 'quantization_type': None}",38,23,3206
yanolja/EEVE-Korean-10.8B-v1.0,https://huggingface.co/yanolja/EEVE-Korean-10.8B-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'yanolja/EEVE-Korean-10.8B-v1.0', 'num_gpus': 2, 'quantization_type': None}",30,23,40791
m-a-p/OpenCodeInterpreter-CL-70B,https://huggingface.co/m-a-p/OpenCodeInterpreter-CL-70B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 159, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'm-a-p/OpenCodeInterpreter-CL-70B', 'num_gpus': 2, 'quantization_type': None}",23,23,143
gordicaleksa/YugoGPT,https://huggingface.co/gordicaleksa/YugoGPT,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'gordicaleksa/YugoGPT', 'num_gpus': 1, 'quantization_type': None}",23,23,2888
cognitivecomputations/dolphin-2.6-mixtral-8x7b,https://huggingface.co/cognitivecomputations/dolphin-2.6-mixtral-8x7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'cognitivecomputations/dolphin-2.6-mixtral-8x7b', 'num_gpus': 2, 'quantization_type': None}",168,22,2444
NousResearch/Nous-Hermes-2-SOLAR-10.7B,https://huggingface.co/NousResearch/Nous-Hermes-2-SOLAR-10.7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'NousResearch/Nous-Hermes-2-SOLAR-10.7B', 'num_gpus': 2, 'quantization_type': None}",174,22,5520
Crystalcareai/Qwen1.5-8x7b,https://huggingface.co/Crystalcareai/Qwen1.5-8x7b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 115, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'Crystalcareai/Qwen1.5-8x7b', 'num_gpus': 2, 'quantization_type': None}",43,22,1731
kaist-ai/mistral-orpo-beta,https://huggingface.co/kaist-ai/mistral-orpo-beta,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'kaist-ai/mistral-orpo-beta', 'num_gpus': 1, 'quantization_type': None}",22,22,693
Replete-AI/Mistral-Evolved-11b-v0.1,https://huggingface.co/Replete-AI/Mistral-Evolved-11b-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 33, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Replete-AI/Mistral-Evolved-11b-v0.1', 'num_gpus': 2, 'quantization_type': None}",22,22,280
Qwen/Qwen1.5-0.5B-Chat,https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'Qwen/Qwen1.5-0.5B-Chat', 'num_gpus': 1, 'quantization_type': None}",33,21,55398
sail/Sailor-7B,https://huggingface.co/sail/Sailor-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'sail/Sailor-7B', 'num_gpus': 1, 'quantization_type': None}",21,21,2062
Gustavosta/MagicPrompt-Stable-Diffusion,https://huggingface.co/Gustavosta/MagicPrompt-Stable-Diffusion,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 1, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'Gustavosta/MagicPrompt-Stable-Diffusion', 'num_gpus': 1, 'quantization_type': None}",637,20,30733
tiiuae/falcon-180B,https://huggingface.co/tiiuae/falcon-180B,PyTorch TGI GPU,unknown,True,False,"{'estimated_memory_in_gigabytes': 426, 'gcp_instance': 'a2-ultragpu-8g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'tiiuae/falcon-180B', 'num_gpus': 8, 'quantization_type': None}",1058,20,13882
meta-llama/LlamaGuard-7b,https://huggingface.co/meta-llama/LlamaGuard-7b,PyTorch TGI GPU,llama2,True,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'meta-llama/LlamaGuard-7b', 'num_gpus': 1, 'quantization_type': None}",145,20,10572
MediaTek-Research/Breeze-7B-Instruct-v0_1,https://huggingface.co/MediaTek-Research/Breeze-7B-Instruct-v0_1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'MediaTek-Research/Breeze-7B-Instruct-v0_1', 'num_gpus': 1, 'quantization_type': None}",64,20,4329
dreamgen/opus-v1.2-7b,https://huggingface.co/dreamgen/opus-v1.2-7b,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'dreamgen/opus-v1.2-7b', 'num_gpus': 1, 'quantization_type': None}",20,20,373
meta-llama/Llama-2-13b-hf,https://huggingface.co/meta-llama/Llama-2-13b-hf,PyTorch TGI GPU,N/A,True,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'meta-llama/Llama-2-13b-hf', 'num_gpus': 2, 'quantization_type': None}",518,19,188608
microsoft/Orca-2-13b,https://huggingface.co/microsoft/Orca-2-13b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'microsoft/Orca-2-13b', 'num_gpus': 2, 'quantization_type': None}",636,19,61007
TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ,https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ', 'num_gpus': 2, 'quantization_type': 'gptq'}",114,19,78718
cognitivecomputations/dolphin-2.7-mixtral-8x7b,https://huggingface.co/cognitivecomputations/dolphin-2.7-mixtral-8x7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'cognitivecomputations/dolphin-2.7-mixtral-8x7b', 'num_gpus': 2, 'quantization_type': None}",124,19,9680
riotu-lab/ArabianGPT-03B,https://huggingface.co/riotu-lab/ArabianGPT-03B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 2, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'riotu-lab/ArabianGPT-03B', 'num_gpus': 1, 'quantization_type': None}",19,19,2374
defog/sqlcoder-70b-alpha,https://huggingface.co/defog/sqlcoder-70b-alpha,PyTorch TGI GPU,cc-by-sa-4.0,False,False,"{'estimated_memory_in_gigabytes': 159, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'defog/sqlcoder-70b-alpha', 'num_gpus': 2, 'quantization_type': None}",165,19,4018
jondurbin/airoboros-34b-3.2,https://huggingface.co/jondurbin/airoboros-34b-3.2,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 122, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'jondurbin/airoboros-34b-3.2', 'num_gpus': 2, 'quantization_type': None}",19,19,59
cognitivecomputations/WizardLM-7B-Uncensored,https://huggingface.co/cognitivecomputations/WizardLM-7B-Uncensored,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'cognitivecomputations/WizardLM-7B-Uncensored', 'num_gpus': 1, 'quantization_type': None}",406,18,3670
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', 'num_gpus': 1, 'quantization_type': None}",124,18,73614
utrobinmv/t5_translate_en_ru_zh_large_1024,https://huggingface.co/utrobinmv/t5_translate_en_ru_zh_large_1024,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', 'num_gpus': 1, 'quantization_type': None}",23,18,27414
Equall/Saul-Base,https://huggingface.co/Equall/Saul-Base,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Equall/Saul-Base', 'num_gpus': 1, 'quantization_type': None}",18,18,883
bardsai/jaskier-7b-dpo-v5.6,https://huggingface.co/bardsai/jaskier-7b-dpo-v5.6,PyTorch TGI GPU,cc-by-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'bardsai/jaskier-7b-dpo-v5.6', 'num_gpus': 1, 'quantization_type': None}",24,18,9193
MBZUAI/MobiLlama-1B-Chat,https://huggingface.co/MBZUAI/MobiLlama-1B-Chat,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 4, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'MBZUAI/MobiLlama-1B-Chat', 'num_gpus': 1, 'quantization_type': None}",18,18,315
cognitivecomputations/dolphin-2.8-experiment26-7b,https://huggingface.co/cognitivecomputations/dolphin-2.8-experiment26-7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/dolphin-2.8-experiment26-7b', 'num_gpus': 1, 'quantization_type': None}",18,18,1790
yam-peleg/Hebrew-Gemma-11B-Instruct,https://huggingface.co/yam-peleg/Hebrew-Gemma-11B-Instruct,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 45, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'yam-peleg/Hebrew-Gemma-11B-Instruct', 'num_gpus': 2, 'quantization_type': None}",18,18,538
saltlux/luxia-21.4b-alignment-v1.0,https://huggingface.co/saltlux/luxia-21.4b-alignment-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 58, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'saltlux/luxia-21.4b-alignment-v1.0', 'num_gpus': 1, 'quantization_type': None}",18,18,1308
TheDrummer/Moistral-11B-v1,https://huggingface.co/TheDrummer/Moistral-11B-v1,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheDrummer/Moistral-11B-v1', 'num_gpus': 2, 'quantization_type': None}",18,18,158
distilbert/distilgpt2,https://huggingface.co/distilbert/distilgpt2,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 1, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'distilbert/distilgpt2', 'num_gpus': 1, 'quantization_type': None}",336,17,2217018
tiiuae/falcon-7b-instruct,https://huggingface.co/tiiuae/falcon-7b-instruct,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 18, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'tiiuae/falcon-7b-instruct', 'num_gpus': 1, 'quantization_type': None}",844,17,242927
FlagAlpha/Llama2-Chinese-7b-Chat,https://huggingface.co/FlagAlpha/Llama2-Chinese-7b-Chat,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'FlagAlpha/Llama2-Chinese-7b-Chat', 'num_gpus': 1, 'quantization_type': None}",188,17,5845
Falconsai/text_summarization,https://huggingface.co/Falconsai/text_summarization,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'FlagAlpha/Llama2-Chinese-7b-Chat', 'num_gpus': 1, 'quantization_type': None}",97,17,54975
NousResearch/Yarn-Mistral-7b-128k,https://huggingface.co/NousResearch/Yarn-Mistral-7b-128k,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'NousResearch/Yarn-Mistral-7b-128k', 'num_gpus': 1, 'quantization_type': None}",542,17,121472
01-ai/Yi-6B-Chat,https://huggingface.co/01-ai/Yi-6B-Chat,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 20, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': '01-ai/Yi-6B-Chat', 'num_gpus': 1, 'quantization_type': None}",49,17,18366
Trendyol/Trendyol-LLM-7b-chat-v0.1,https://huggingface.co/Trendyol/Trendyol-LLM-7b-chat-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Trendyol/Trendyol-LLM-7b-chat-v0.1', 'num_gpus': 1, 'quantization_type': None}",95,17,9035
tokyotech-llm/Swallow-MS-7b-v0.1,https://huggingface.co/tokyotech-llm/Swallow-MS-7b-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'tokyotech-llm/Swallow-MS-7b-v0.1', 'num_gpus': 1, 'quantization_type': None}",17,17,3545
GritLM/GritLM-7B,https://huggingface.co/GritLM/GritLM-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'GritLM/GritLM-7B', 'num_gpus': 1, 'quantization_type': None}",38,17,15460
ContextualAI/Contextual_KTO_Mistral_PairRM,https://huggingface.co/ContextualAI/Contextual_KTO_Mistral_PairRM,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ContextualAI/Contextual_KTO_Mistral_PairRM', 'num_gpus': 1, 'quantization_type': None}",17,17,1602
Trendyol/Trendyol-LLM-7b-chat-v1.0,https://huggingface.co/Trendyol/Trendyol-LLM-7b-chat-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Trendyol/Trendyol-LLM-7b-chat-v1.0', 'num_gpus': 1, 'quantization_type': None}",17,17,1256
codellama/CodeLlama-7b-hf,https://huggingface.co/codellama/CodeLlama-7b-hf,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'codellama/CodeLlama-7b-hf', 'num_gpus': 1, 'quantization_type': None}",269,16,312303
HuggingFaceH4/zephyr-7b-alpha,https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'HuggingFaceH4/zephyr-7b-alpha', 'num_gpus': 1, 'quantization_type': None}",1059,16,117515
deepseek-ai/deepseek-coder-1.3b-instruct,https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'deepseek-ai/deepseek-coder-1.3b-instruct', 'num_gpus': 1, 'quantization_type': None}",70,16,17479
codefuse-ai/CodeFuse-DeepSeek-33B,https://huggingface.co/codefuse-ai/CodeFuse-DeepSeek-33B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 78, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'codefuse-ai/CodeFuse-DeepSeek-33B', 'num_gpus': 1, 'quantization_type': None}",40,16,602
h2oai/h2o-danube-1.8b-chat,https://huggingface.co/h2oai/h2o-danube-1.8b-chat,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 10, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'h2oai/h2o-danube-1.8b-chat', 'num_gpus': 1, 'quantization_type': None}",46,16,12830
abacusai/TheProfessor-155b,https://huggingface.co/abacusai/TheProfessor-155b,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 508, 'gcp_instance': 'a2-ultragpu-8g', 'max_batch_prefill_tokens': 32768, 'max_input_length': 4000, 'max_total_tokens': 4096, 'model_id': 'abacusai/TheProfessor-155b', 'num_gpus': 8, 'quantization_type': None}",78,16,1273
WhiteRabbitNeo/WhiteRabbitNeo-33B-v1.5,https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-33B-v1.5,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 78, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'WhiteRabbitNeo/WhiteRabbitNeo-33B-v1.5', 'num_gpus': 1, 'quantization_type': None}",61,16,275
AlexWortega/miqu-1-70b-AQLM-2Bit-1x16-hf,https://huggingface.co/AlexWortega/miqu-1-70b-AQLM-2Bit-1x16-hf,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 73, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'AlexWortega/miqu-1-70b-AQLM-2Bit-1x16-hf', 'num_gpus': 1, 'quantization_type': 'aqlm'}",23,16,121
IlyaGusev/saiga_gemma_9b,https://huggingface.co/IlyaGusev/saiga_gemma_9b,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'IlyaGusev/saiga_gemma_9b', 'num_gpus': 1, 'quantization_type': None}",16,16,321
wolfram/miqu-1-103b,https://huggingface.co/wolfram/miqu-1-103b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 280, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'wolfram/miqu-1-103b', 'num_gpus': 4, 'quantization_type': None}",16,16,653
google-t5/t5-small,https://huggingface.co/google-t5/t5-small,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 280, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'wolfram/miqu-1-103b', 'num_gpus': 4, 'quantization_type': None}",226,15,3887371
tiiuae/falcon-40b,https://huggingface.co/tiiuae/falcon-40b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 100, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'tiiuae/falcon-40b', 'num_gpus': 2, 'quantization_type': None}",2387,15,40700
Qwen/Qwen1.5-72B,https://huggingface.co/Qwen/Qwen1.5-72B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 242, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'Qwen/Qwen1.5-72B', 'num_gpus': 4, 'quantization_type': None}",36,15,9613
deepseek-ai/deepseek-coder-7b-instruct-v1.5,https://huggingface.co/deepseek-ai/deepseek-coder-7b-instruct-v1.5,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'deepseek-ai/deepseek-coder-7b-instruct-v1.5', 'num_gpus': 1, 'quantization_type': None}",62,15,10661
m-a-p/OpenCodeInterpreter-DS-1.3B,https://huggingface.co/m-a-p/OpenCodeInterpreter-DS-1.3B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'm-a-p/OpenCodeInterpreter-DS-1.3B', 'num_gpus': 1, 'quantization_type': None}",15,15,1753
INSAIT-Institute/BgGPT-7B-Instruct-v0.2,https://huggingface.co/INSAIT-Institute/BgGPT-7B-Instruct-v0.2,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'INSAIT-Institute/BgGPT-7B-Instruct-v0.2', 'num_gpus': 1, 'quantization_type': None}",15,15,2492
rhysjones/phi-2-orange-v2,https://huggingface.co/rhysjones/phi-2-orange-v2,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 7, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'rhysjones/phi-2-orange-v2', 'num_gpus': 1, 'quantization_type': None}",15,15,2422
MediaTek-Research/Breeze-7B-Instruct-v1_0,https://huggingface.co/MediaTek-Research/Breeze-7B-Instruct-v1_0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'MediaTek-Research/Breeze-7B-Instruct-v1_0', 'num_gpus': 1, 'quantization_type': None}",15,15,2783
FreedomIntelligence/Apollo-7B,https://huggingface.co/FreedomIntelligence/Apollo-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'FreedomIntelligence/Apollo-7B', 'num_gpus': 1, 'quantization_type': None}",15,15,187
ezelikman/quietstar-8-ahead,https://huggingface.co/ezelikman/quietstar-8-ahead,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ezelikman/quietstar-8-ahead', 'num_gpus': 1, 'quantization_type': None}",15,15,221
openai-community/gpt2-xl,https://huggingface.co/openai-community/gpt2-xl,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 4, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'openai-community/gpt2-xl', 'num_gpus': 1, 'quantization_type': None}",259,14,187411
NousResearch/Llama-2-7b-hf,https://huggingface.co/NousResearch/Llama-2-7b-hf,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'NousResearch/Llama-2-7b-hf', 'num_gpus': 1, 'quantization_type': None}",125,14,111932
NousResearch/Llama-2-7b-chat-hf,https://huggingface.co/NousResearch/Llama-2-7b-chat-hf,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'NousResearch/Llama-2-7b-chat-hf', 'num_gpus': 1, 'quantization_type': None}",125,14,243744
HuggingFaceM4/idefics-9b-instruct,https://huggingface.co/HuggingFaceM4/idefics-9b-instruct,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'HuggingFaceM4/idefics-9b-instruct', 'num_gpus': 1, 'quantization_type': None}",86,14,13635
mychen76/mistral7b_ocr_to_json_v1,https://huggingface.co/mychen76/mistral7b_ocr_to_json_v1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'mychen76/mistral7b_ocr_to_json_v1', 'num_gpus': 1, 'quantization_type': None}",44,14,1583
LumiOpen/Poro-34B,https://huggingface.co/LumiOpen/Poro-34B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 78, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'LumiOpen/Poro-34B', 'num_gpus': 1, 'quantization_type': None}",89,14,5564
SanjiWatsuki/Kunoichi-DPO-v2-7B,https://huggingface.co/SanjiWatsuki/Kunoichi-DPO-v2-7B,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'SanjiWatsuki/Kunoichi-DPO-v2-7B', 'num_gpus': 1, 'quantization_type': None}",42,14,6383
Qwen/Qwen1.5-4B-Chat,https://huggingface.co/Qwen/Qwen1.5-4B-Chat,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'Qwen/Qwen1.5-4B-Chat', 'num_gpus': 1, 'quantization_type': None}",25,14,13651
Qwen/Qwen1.5-72B-Chat-GPTQ-Int4,https://huggingface.co/Qwen/Qwen1.5-72B-Chat-GPTQ-Int4,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 75, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Qwen/Qwen1.5-72B-Chat-GPTQ-Int4', 'num_gpus': 1, 'quantization_type': 'gptq'}",25,14,24803
brucethemoose/Yi-34B-200K-RPMerge,https://huggingface.co/brucethemoose/Yi-34B-200K-RPMerge,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 122, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'brucethemoose/Yi-34B-200K-RPMerge', 'num_gpus': 2, 'quantization_type': None}",42,14,1393
cognitivecomputations/fc-dolphin-2.6-mistral-7b-dpo-laser,https://huggingface.co/cognitivecomputations/fc-dolphin-2.6-mistral-7b-dpo-laser,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/fc-dolphin-2.6-mistral-7b-dpo-laser', 'num_gpus': 1, 'quantization_type': None}",17,14,173
ytu-ce-cosmos/turkish-gpt2-large,https://huggingface.co/ytu-ce-cosmos/turkish-gpt2-large,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 3, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'ytu-ce-cosmos/turkish-gpt2-large', 'num_gpus': 1, 'quantization_type': None}",21,14,6207
INSAIT-Institute/BgGPT-7B-Instruct-v0.1,https://huggingface.co/INSAIT-Institute/BgGPT-7B-Instruct-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'INSAIT-Institute/BgGPT-7B-Instruct-v0.1', 'num_gpus': 1, 'quantization_type': None}",41,14,2936
tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1,https://huggingface.co/tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1', 'num_gpus': 2, 'quantization_type': None}",14,14,1369
OPI-PG/Qra-1b,https://huggingface.co/OPI-PG/Qra-1b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'OPI-PG/Qra-1b', 'num_gpus': 1, 'quantization_type': None}",14,14,9638
migtissera/Tess-70B-v1.6,https://huggingface.co/migtissera/Tess-70B-v1.6,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 158, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'migtissera/Tess-70B-v1.6', 'num_gpus': 2, 'quantization_type': None}",14,14,1389
openai-community/gpt2-large,https://huggingface.co/openai-community/gpt2-large,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 3, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'openai-community/gpt2-large', 'num_gpus': 1, 'quantization_type': None}",211,13,591942
google-t5/t5-base,https://huggingface.co/google-t5/t5-base,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 3, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'openai-community/gpt2-large', 'num_gpus': 1, 'quantization_type': None}",418,13,2790525
DeepFloyd/t5-v1_1-xxl,https://huggingface.co/DeepFloyd/t5-v1_1-xxl,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 3, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'openai-community/gpt2-large', 'num_gpus': 1, 'quantization_type': None}",29,13,13929
ai-forever/ruGPT-3.5-13B,https://huggingface.co/ai-forever/ruGPT-3.5-13B,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 32, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'ai-forever/ruGPT-3.5-13B', 'num_gpus': 2, 'quantization_type': None}",213,13,3819
cognitivecomputations/WizardLM-13B-Uncensored,https://huggingface.co/cognitivecomputations/WizardLM-13B-Uncensored,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 32, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'cognitivecomputations/WizardLM-13B-Uncensored', 'num_gpus': 2, 'quantization_type': None}",513,13,1485
TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ,https://huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 31, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ', 'num_gpus': 2, 'quantization_type': 'gptq'}",532,13,3604
hfl/chinese-alpaca-2-7b,https://huggingface.co/hfl/chinese-alpaca-2-7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'hfl/chinese-alpaca-2-7b', 'num_gpus': 1, 'quantization_type': None}",152,13,4485
TheBloke/MythoMax-L2-13B-GPTQ,https://huggingface.co/TheBloke/MythoMax-L2-13B-GPTQ,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 19, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/MythoMax-L2-13B-GPTQ', 'num_gpus': 1, 'quantization_type': 'gptq'}",151,13,34215
WizardLM/WizardCoder-Python-34B-V1.0,https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'WizardLM/WizardCoder-Python-34B-V1.0', 'num_gpus': 1, 'quantization_type': None}",736,13,5324
oobabooga/CodeBooga-34B-v0.1,https://huggingface.co/oobabooga/CodeBooga-34B-v0.1,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'oobabooga/CodeBooga-34B-v0.1', 'num_gpus': 1, 'quantization_type': None}",127,13,2860
macadeliccc/laser-dolphin-mixtral-2x7b-dpo,https://huggingface.co/macadeliccc/laser-dolphin-mixtral-2x7b-dpo,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 40, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'macadeliccc/laser-dolphin-mixtral-2x7b-dpo', 'num_gpus': 2, 'quantization_type': None}",44,13,3042
Qwen/Qwen1.5-14B,https://huggingface.co/Qwen/Qwen1.5-14B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'Qwen/Qwen1.5-14B', 'num_gpus': 2, 'quantization_type': None}",20,13,8243
croissantllm/CroissantLLMChat-v0.1,https://huggingface.co/croissantllm/CroissantLLMChat-v0.1,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'croissantllm/CroissantLLMChat-v0.1', 'num_gpus': 1, 'quantization_type': None}",33,13,9205
ZySec-AI/ZySec-7B,https://huggingface.co/ZySec-AI/ZySec-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ZySec-AI/ZySec-7B', 'num_gpus': 1, 'quantization_type': None}",22,13,94039
chatdb/natural-sql-7b,https://huggingface.co/chatdb/natural-sql-7b,PyTorch TGI GPU,cc-by-sa-4.0,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'chatdb/natural-sql-7b', 'num_gpus': 1, 'quantization_type': None}",82,13,3070
occiglot/occiglot-7b-eu5,https://huggingface.co/occiglot/occiglot-7b-eu5,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'occiglot/occiglot-7b-eu5', 'num_gpus': 1, 'quantization_type': None}",18,13,694
dreamgen/opus-v1-34b,https://huggingface.co/dreamgen/opus-v1-34b,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 122, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'dreamgen/opus-v1-34b', 'num_gpus': 2, 'quantization_type': None}",13,13,116
yanolja/EEVE-Korean-Instruct-10.8B-v1.0,https://huggingface.co/yanolja/EEVE-Korean-Instruct-10.8B-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'yanolja/EEVE-Korean-Instruct-10.8B-v1.0', 'num_gpus': 2, 'quantization_type': None}",13,13,12291
mlabonne/Gemmalpaca-2B,https://huggingface.co/mlabonne/Gemmalpaca-2B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'mlabonne/Gemmalpaca-2B', 'num_gpus': 1, 'quantization_type': None}",13,13,2432
MBZUAI/MobiLlama-1B,https://huggingface.co/MBZUAI/MobiLlama-1B,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'MBZUAI/MobiLlama-1B', 'num_gpus': 1, 'quantization_type': None}",13,13,196
MBZUAI/MobiLlama-05B-Chat,https://huggingface.co/MBZUAI/MobiLlama-05B-Chat,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 4, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'MBZUAI/MobiLlama-05B-Chat', 'num_gpus': 1, 'quantization_type': None}",13,13,459
TIGER-Lab/StructLM-7B,https://huggingface.co/TIGER-Lab/StructLM-7B,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'TIGER-Lab/StructLM-7B', 'num_gpus': 1, 'quantization_type': None}",13,13,212
m-a-p/OpenCodeInterpreter-SC2-7B,https://huggingface.co/m-a-p/OpenCodeInterpreter-SC2-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'm-a-p/OpenCodeInterpreter-SC2-7B', 'num_gpus': 1, 'quantization_type': None}",13,13,22
occiglot/occiglot-7b-de-en-instruct,https://huggingface.co/occiglot/occiglot-7b-de-en-instruct,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'occiglot/occiglot-7b-de-en-instruct', 'num_gpus': 1, 'quantization_type': None}",13,13,465
cloudyu/mistral_pretrain_demo,https://huggingface.co/cloudyu/mistral_pretrain_demo,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 9, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cloudyu/mistral_pretrain_demo', 'num_gpus': 1, 'quantization_type': None}",13,13,381
sophosympatheia/Midnight-Miqu-70B-v1.5,https://huggingface.co/sophosympatheia/Midnight-Miqu-70B-v1.5,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 158, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'sophosympatheia/Midnight-Miqu-70B-v1.5', 'num_gpus': 2, 'quantization_type': None}",13,13,86
Rakuten/RakutenAI-7B,https://huggingface.co/Rakuten/RakutenAI-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Rakuten/RakutenAI-7B', 'num_gpus': 1, 'quantization_type': None}",13,13,24
facebook/opt-2.7b,https://huggingface.co/facebook/opt-2.7b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 7, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'facebook/opt-2.7b', 'num_gpus': 1, 'quantization_type': None}",72,12,55992
TheBloke/Llama-2-7B-Chat-GPTQ,https://huggingface.co/TheBloke/Llama-2-7B-Chat-GPTQ,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 12, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/Llama-2-7B-Chat-GPTQ', 'num_gpus': 1, 'quantization_type': 'gptq'}",235,12,460927
togethercomputer/LLaMA-2-7B-32K,https://huggingface.co/togethercomputer/LLaMA-2-7B-32K,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'togethercomputer/LLaMA-2-7B-32K', 'num_gpus': 1, 'quantization_type': None}",508,12,51821
alpindale/goliath-120b,https://huggingface.co/alpindale/goliath-120b,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 310, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'alpindale/goliath-120b', 'num_gpus': 4, 'quantization_type': None}",198,12,3639
ise-uiuc/Magicoder-S-DS-6.7B,https://huggingface.co/ise-uiuc/Magicoder-S-DS-6.7B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ise-uiuc/Magicoder-S-DS-6.7B', 'num_gpus': 1, 'quantization_type': None}",188,12,8541
TheBloke/dolphin-2.5-mixtral-8x7b-GPTQ,https://huggingface.co/TheBloke/dolphin-2.5-mixtral-8x7b-GPTQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/dolphin-2.5-mixtral-8x7b-GPTQ', 'num_gpus': 2, 'quantization_type': 'gptq'}",78,12,391
SanjiWatsuki/Silicon-Maid-7B,https://huggingface.co/SanjiWatsuki/Silicon-Maid-7B,PyTorch TGI GPU,cc-by-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'SanjiWatsuki/Silicon-Maid-7B', 'num_gpus': 1, 'quantization_type': None}",72,12,4539
segolilylabs/Lily-Cybersecurity-7B-v0.2,https://huggingface.co/segolilylabs/Lily-Cybersecurity-7B-v0.2,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'segolilylabs/Lily-Cybersecurity-7B-v0.2', 'num_gpus': 1, 'quantization_type': None}",23,12,548
unsloth/mistral-7b-instruct-v0.2-bnb-4bit,https://huggingface.co/unsloth/mistral-7b-instruct-v0.2-bnb-4bit,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'unsloth/mistral-7b-instruct-v0.2-bnb-4bit', 'num_gpus': 1, 'quantization_type': 'bitsandbytes'}",16,12,100009
abacusai/Smaug-34B-v0.1,https://huggingface.co/abacusai/Smaug-34B-v0.1,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 86, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'abacusai/Smaug-34B-v0.1', 'num_gpus': 2, 'quantization_type': None}",46,12,5060
SeaLLMs/SeaLLM-7B-v2,https://huggingface.co/SeaLLMs/SeaLLM-7B-v2,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'SeaLLMs/SeaLLM-7B-v2', 'num_gpus': 1, 'quantization_type': None}",43,12,11793
alchemonaut/QuartetAnemoi-70B-t0.0001,https://huggingface.co/alchemonaut/QuartetAnemoi-70B-t0.0001,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 158, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'alchemonaut/QuartetAnemoi-70B-t0.0001', 'num_gpus': 2, 'quantization_type': None}",23,12,1673
USAIL-HKUSTGZ/LLMLight-LightGPT,https://huggingface.co/USAIL-HKUSTGZ/LLMLight-LightGPT,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'USAIL-HKUSTGZ/LLMLight-LightGPT', 'num_gpus': 2, 'quantization_type': None}",12,12,34
m-a-p/OpenCodeInterpreter-CL-34B,https://huggingface.co/m-a-p/OpenCodeInterpreter-CL-34B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'm-a-p/OpenCodeInterpreter-CL-34B', 'num_gpus': 1, 'quantization_type': None}",12,12,180
mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-2bit-metaoffload-HQQ,https://huggingface.co/mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-2bit-metaoffload-HQQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-2bit-metaoffload-HQQ', 'num_gpus': 2, 'quantization_type': None}",12,12,61
TIGER-Lab/StructLM-34B,https://huggingface.co/TIGER-Lab/StructLM-34B,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'TIGER-Lab/StructLM-34B', 'num_gpus': 1, 'quantization_type': None}",12,12,70
cognitivecomputations/dolphin-2.8-experiment26-7b-preview,https://huggingface.co/cognitivecomputations/dolphin-2.8-experiment26-7b-preview,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/dolphin-2.8-experiment26-7b-preview', 'num_gpus': 1, 'quantization_type': None}",12,12,2129
MTSAIR/multi_verse_model,https://huggingface.co/MTSAIR/multi_verse_model,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'MTSAIR/multi_verse_model', 'num_gpus': 1, 'quantization_type': None}",12,12,1392
M4-ai/tau-0.5B,https://huggingface.co/M4-ai/tau-0.5B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'M4-ai/tau-0.5B', 'num_gpus': 1, 'quantization_type': None}",12,12,2234
Rakuten/RakutenAI-7B-chat,https://huggingface.co/Rakuten/RakutenAI-7B-chat,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Rakuten/RakutenAI-7B-chat', 'num_gpus': 1, 'quantization_type': None}",12,12,53
mosaicml/mpt-7b-storywriter,https://huggingface.co/mosaicml/mpt-7b-storywriter,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'mosaicml/mpt-7b-storywriter', 'num_gpus': 1, 'quantization_type': None}",767,11,6898
grammarly/coedit-large,https://huggingface.co/grammarly/coedit-large,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'mosaicml/mpt-7b-storywriter', 'num_gpus': 1, 'quantization_type': None}",82,11,7284
AdaptLLM/finance-LLM,https://huggingface.co/AdaptLLM/finance-LLM,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'AdaptLLM/finance-LLM', 'num_gpus': 1, 'quantization_type': None}",71,11,1788
teknium/Mistral-Trismegistus-7B,https://huggingface.co/teknium/Mistral-Trismegistus-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'teknium/Mistral-Trismegistus-7B', 'num_gpus': 1, 'quantization_type': None}",175,11,1580
amazon/MistralLite,https://huggingface.co/amazon/MistralLite,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'amazon/MistralLite', 'num_gpus': 1, 'quantization_type': None}",416,11,135946
KoboldAI/LLaMA2-13B-Tiefighter,https://huggingface.co/KoboldAI/LLaMA2-13B-Tiefighter,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'KoboldAI/LLaMA2-13B-Tiefighter', 'num_gpus': 2, 'quantization_type': None}",65,11,12311
01-ai/Yi-6B-200K,https://huggingface.co/01-ai/Yi-6B-200K,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': '01-ai/Yi-6B-200K', 'num_gpus': 1, 'quantization_type': None}",165,11,7659
Intel/neural-chat-7b-v3-1,https://huggingface.co/Intel/neural-chat-7b-v3-1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Intel/neural-chat-7b-v3-1', 'num_gpus': 1, 'quantization_type': None}",528,11,14776
AdaptLLM/finance-chat,https://huggingface.co/AdaptLLM/finance-chat,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'AdaptLLM/finance-chat', 'num_gpus': 1, 'quantization_type': None}",46,11,5661
TheBloke/Mixtral-8x7B-Instruct-v0.1-AWQ,https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-AWQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/Mixtral-8x7B-Instruct-v0.1-AWQ', 'num_gpus': 2, 'quantization_type': 'awq'}",45,11,130062
cognitivecomputations/dolphin-2.6-mistral-7b-dpo-laser,https://huggingface.co/cognitivecomputations/dolphin-2.6-mistral-7b-dpo-laser,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/dolphin-2.6-mistral-7b-dpo-laser', 'num_gpus': 1, 'quantization_type': None}",102,11,11516
Qwen/Qwen1.5-1.8B-Chat,https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'Qwen/Qwen1.5-1.8B-Chat', 'num_gpus': 1, 'quantization_type': None}",28,11,30337
HuggingFaceH4/zephyr-7b-gemma-sft-v0.1,https://huggingface.co/HuggingFaceH4/zephyr-7b-gemma-sft-v0.1,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 20, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'HuggingFaceH4/zephyr-7b-gemma-sft-v0.1', 'num_gpus': 1, 'quantization_type': None}",11,11,2510
Trendyol/Trendyol-LLM-7b-chat-dpo-v1.0,https://huggingface.co/Trendyol/Trendyol-LLM-7b-chat-dpo-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 18, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'Trendyol/Trendyol-LLM-7b-chat-dpo-v1.0', 'num_gpus': 1, 'quantization_type': None}",11,11,697
l3utterfly/mistral-7b-v0.1-layla-v4-chatml,https://huggingface.co/l3utterfly/mistral-7b-v0.1-layla-v4-chatml,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'l3utterfly/mistral-7b-v0.1-layla-v4-chatml', 'num_gpus': 1, 'quantization_type': None}",11,11,596
google/flan-t5-small,https://huggingface.co/google/flan-t5-small,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'l3utterfly/mistral-7b-v0.1-layla-v4-chatml', 'num_gpus': 1, 'quantization_type': None}",184,10,516308
databricks/dolly-v2-12b,https://huggingface.co/databricks/dolly-v2-12b,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 29, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'databricks/dolly-v2-12b', 'num_gpus': 2, 'quantization_type': None}",1924,10,7325
TheBloke/Wizard-Vicuna-7B-Uncensored-GPTQ,https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GPTQ,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 7, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'TheBloke/Wizard-Vicuna-7B-Uncensored-GPTQ', 'num_gpus': 1, 'quantization_type': 'gptq'}",149,10,445237
tiiuae/falcon-40b-instruct,https://huggingface.co/tiiuae/falcon-40b-instruct,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 100, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'tiiuae/falcon-40b-instruct', 'num_gpus': 2, 'quantization_type': None}",1162,10,918681
NousResearch/Nous-Hermes-Llama2-13b,https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'NousResearch/Nous-Hermes-Llama2-13b', 'num_gpus': 2, 'quantization_type': None}",284,10,61386
codellama/CodeLlama-7b-Python-hf,https://huggingface.co/codellama/CodeLlama-7b-Python-hf,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'codellama/CodeLlama-7b-Python-hf', 'num_gpus': 1, 'quantization_type': None}",117,10,21043
codellama/CodeLlama-7b-Instruct-hf,https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'codellama/CodeLlama-7b-Instruct-hf', 'num_gpus': 1, 'quantization_type': None}",170,10,66047
PygmalionAI/mythalion-13b,https://huggingface.co/PygmalionAI/mythalion-13b,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'PygmalionAI/mythalion-13b', 'num_gpus': 2, 'quantization_type': None}",124,10,5820
microsoft/Orca-2-7b,https://huggingface.co/microsoft/Orca-2-7b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'microsoft/Orca-2-7b', 'num_gpus': 1, 'quantization_type': None}",199,10,12509
TheBloke/Mistral-7B-Instruct-v0.2-GPTQ,https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GPTQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/Mistral-7B-Instruct-v0.2-GPTQ', 'num_gpus': 1, 'quantization_type': 'gptq'}",28,10,53639
scb10x/typhoon-7b,https://huggingface.co/scb10x/typhoon-7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'scb10x/typhoon-7b', 'num_gpus': 1, 'quantization_type': None}",70,10,12566
semantixai/LloroV2,https://huggingface.co/semantixai/LloroV2,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'semantixai/LloroV2', 'num_gpus': 1, 'quantization_type': None}",14,10,344
Wanfq/FuseLLM-7B,https://huggingface.co/Wanfq/FuseLLM-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'Wanfq/FuseLLM-7B', 'num_gpus': 1, 'quantization_type': None}",18,10,3542
Qwen/Qwen1.5-7B,https://huggingface.co/Qwen/Qwen1.5-7B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Qwen/Qwen1.5-7B', 'num_gpus': 1, 'quantization_type': None}",18,10,15012
h2oai/h2o-danube-1.8b-base,https://huggingface.co/h2oai/h2o-danube-1.8b-base,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 10, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'h2oai/h2o-danube-1.8b-base', 'num_gpus': 1, 'quantization_type': None}",31,10,9989
nakodanei/Blue-Orchid-2x7b,https://huggingface.co/nakodanei/Blue-Orchid-2x7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 40, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'nakodanei/Blue-Orchid-2x7b', 'num_gpus': 2, 'quantization_type': None}",15,10,111
nvidia/OpenMath-Mistral-7B-v0.1-hf,https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'nvidia/OpenMath-Mistral-7B-v0.1-hf', 'num_gpus': 1, 'quantization_type': None}",13,10,2551
ibivibiv/alpaca-dragon-72b-v1,https://huggingface.co/ibivibiv/alpaca-dragon-72b-v1,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 318, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 32768, 'max_input_length': 4000, 'max_total_tokens': 4096, 'model_id': 'ibivibiv/alpaca-dragon-72b-v1', 'num_gpus': 4, 'quantization_type': None}",19,10,2758
Vikhrmodels/Vikhr-7B-instruct_0.2,https://huggingface.co/Vikhrmodels/Vikhr-7B-instruct_0.2,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'Vikhrmodels/Vikhr-7B-instruct_0.2', 'num_gpus': 1, 'quantization_type': None}",17,10,960
yaofu/llama-2-7b-80k,https://huggingface.co/yaofu/llama-2-7b-80k,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'yaofu/llama-2-7b-80k', 'num_gpus': 1, 'quantization_type': None}",12,10,401
abacusai/Smaug-Mixtral-v0.1,https://huggingface.co/abacusai/Smaug-Mixtral-v0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'abacusai/Smaug-Mixtral-v0.1', 'num_gpus': 2, 'quantization_type': None}",10,10,3689
yanolja/EEVE-Korean-Instruct-2.8B-v1.0,https://huggingface.co/yanolja/EEVE-Korean-Instruct-2.8B-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 8, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'yanolja/EEVE-Korean-Instruct-2.8B-v1.0', 'num_gpus': 1, 'quantization_type': None}",10,10,2094
FuseAI/OpenChat-3.5-7B-Mixtral,https://huggingface.co/FuseAI/OpenChat-3.5-7B-Mixtral,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'FuseAI/OpenChat-3.5-7B-Mixtral', 'num_gpus': 1, 'quantization_type': None}",10,10,1635
VAGOsolutions/SauerkrautLM-Gemma-7b,https://huggingface.co/VAGOsolutions/SauerkrautLM-Gemma-7b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'VAGOsolutions/SauerkrautLM-Gemma-7b', 'num_gpus': 1, 'quantization_type': None}",10,10,1969
Severian/Nexus-IKM-Mistral-7B-Pytorch,https://huggingface.co/Severian/Nexus-IKM-Mistral-7B-Pytorch,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Severian/Nexus-IKM-Mistral-7B-Pytorch', 'num_gpus': 1, 'quantization_type': None}",10,10,1547
abacusai/Liberated-Qwen1.5-14B,https://huggingface.co/abacusai/Liberated-Qwen1.5-14B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'abacusai/Liberated-Qwen1.5-14B', 'num_gpus': 2, 'quantization_type': None}",10,10,2291
Trendyol/Trendyol-LLM-7b-base-v1.0,https://huggingface.co/Trendyol/Trendyol-LLM-7b-base-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Trendyol/Trendyol-LLM-7b-base-v1.0', 'num_gpus': 1, 'quantization_type': None}",10,10,228
abacusai/bigyi-15b,https://huggingface.co/abacusai/bigyi-15b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 41, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'abacusai/bigyi-15b', 'num_gpus': 2, 'quantization_type': None}",10,10,1671
Endevor/InfinityRP-v1-7B,https://huggingface.co/Endevor/InfinityRP-v1-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Endevor/InfinityRP-v1-7B', 'num_gpus': 1, 'quantization_type': None}",10,10,138
arise-sustech/llm4decompile-6.7b-uo,https://huggingface.co/arise-sustech/llm4decompile-6.7b-uo,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'arise-sustech/llm4decompile-6.7b-uo', 'num_gpus': 1, 'quantization_type': None}",10,10,57
EleutherAI/gpt-neox-20b,https://huggingface.co/EleutherAI/gpt-neox-20b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 48, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'EleutherAI/gpt-neox-20b', 'num_gpus': 1, 'quantization_type': None}",483,9,28328
KoboldAI/OPT-13B-Erebus,https://huggingface.co/KoboldAI/OPT-13B-Erebus,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 32, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'KoboldAI/OPT-13B-Erebus', 'num_gpus': 2, 'quantization_type': None}",196,9,58490
google/flan-t5-xl,https://huggingface.co/google/flan-t5-xl,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 32, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'KoboldAI/OPT-13B-Erebus', 'num_gpus': 2, 'quantization_type': None}",404,9,226760
google/flan-ul2,https://huggingface.co/google/flan-ul2,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'google/flan-ul2', 'num_gpus': 2, 'quantization_type': None}",538,9,48615
databricks/dolly-v2-3b,https://huggingface.co/databricks/dolly-v2-3b,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 7, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'databricks/dolly-v2-3b', 'num_gpus': 1, 'quantization_type': None}",269,9,309356
mosaicml/mpt-7b,https://huggingface.co/mosaicml/mpt-7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'mosaicml/mpt-7b', 'num_gpus': 1, 'quantization_type': None}",1133,9,50537
Gryphe/MythoMax-L2-13b,https://huggingface.co/Gryphe/MythoMax-L2-13b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Gryphe/MythoMax-L2-13b', 'num_gpus': 2, 'quantization_type': None}",214,9,77551
princeton-nlp/SWE-Llama-13b,https://huggingface.co/princeton-nlp/SWE-Llama-13b,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 39, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'princeton-nlp/SWE-Llama-13b', 'num_gpus': 2, 'quantization_type': None}",18,9,111
cognitivecomputations/dolphin-2.1-mistral-7b,https://huggingface.co/cognitivecomputations/dolphin-2.1-mistral-7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/dolphin-2.1-mistral-7b', 'num_gpus': 1, 'quantization_type': None}",252,9,63296
kaist-ai/prometheus-13b-v1.0,https://huggingface.co/kaist-ai/prometheus-13b-v1.0,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'kaist-ai/prometheus-13b-v1.0', 'num_gpus': 2, 'quantization_type': None}",94,9,7267
deepseek-ai/deepseek-coder-6.7b-base,https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'deepseek-ai/deepseek-coder-6.7b-base', 'num_gpus': 1, 'quantization_type': None}",60,9,11590
01-ai/Yi-6B,https://huggingface.co/01-ai/Yi-6B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 20, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': '01-ai/Yi-6B', 'num_gpus': 1, 'quantization_type': None}",352,9,16294
TheBloke/Yarn-Mistral-7B-128k-AWQ,https://huggingface.co/TheBloke/Yarn-Mistral-7B-128k-AWQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/Yarn-Mistral-7B-128k-AWQ', 'num_gpus': 1, 'quantization_type': 'awq'}",62,9,795
Nexusflow/NexusRaven-V2-13B,https://huggingface.co/Nexusflow/NexusRaven-V2-13B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 44, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'Nexusflow/NexusRaven-V2-13B', 'num_gpus': 2, 'quantization_type': None}",387,9,53407
Intel/neural-chat-7b-v3-3,https://huggingface.co/Intel/neural-chat-7b-v3-3,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Intel/neural-chat-7b-v3-3', 'num_gpus': 1, 'quantization_type': None}",55,9,9822
TheBloke/Mistral-7B-Instruct-v0.2-AWQ,https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-AWQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/Mistral-7B-Instruct-v0.2-AWQ', 'num_gpus': 1, 'quantization_type': 'awq'}",29,9,64463
rishiraj/CatPPT-base,https://huggingface.co/rishiraj/CatPPT-base,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'rishiraj/CatPPT-base', 'num_gpus': 1, 'quantization_type': None}",40,9,10005
casperhansen/mixtral-instruct-awq,https://huggingface.co/casperhansen/mixtral-instruct-awq,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'casperhansen/mixtral-instruct-awq', 'num_gpus': 2, 'quantization_type': 'awq'}",35,9,13654
OpenPipe/mistral-ft-optimized-1227,https://huggingface.co/OpenPipe/mistral-ft-optimized-1227,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'OpenPipe/mistral-ft-optimized-1227', 'num_gpus': 1, 'quantization_type': None}",74,9,7479
WizardLM/WizardCoder-33B-V1.1,https://huggingface.co/WizardLM/WizardCoder-33B-V1.1,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 78, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'WizardLM/WizardCoder-33B-V1.1', 'num_gpus': 1, 'quantization_type': None}",112,9,1963
meetkai/functionary-small-v2.2,https://huggingface.co/meetkai/functionary-small-v2.2,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'meetkai/functionary-small-v2.2', 'num_gpus': 1, 'quantization_type': None}",19,9,2435
croissantllm/CroissantLLMBase,https://huggingface.co/croissantllm/CroissantLLMBase,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'croissantllm/CroissantLLMBase', 'num_gpus': 1, 'quantization_type': None}",25,9,4110
DiscoResearch/DiscoLM_German_7b_v1,https://huggingface.co/DiscoResearch/DiscoLM_German_7b_v1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'DiscoResearch/DiscoLM_German_7b_v1', 'num_gpus': 1, 'quantization_type': None}",50,9,6832
TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-GPTQ,https://huggingface.co/TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-GPTQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-GPTQ', 'num_gpus': 2, 'quantization_type': 'gptq'}",23,9,95790
ISTA-DASLab/Mixtral-8x7b-AQLM-2Bit-1x16-hf,https://huggingface.co/ISTA-DASLab/Mixtral-8x7b-AQLM-2Bit-1x16-hf,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ISTA-DASLab/Mixtral-8x7b-AQLM-2Bit-1x16-hf', 'num_gpus': 2, 'quantization_type': 'aqlm'}",19,9,1433
GritLM/GritLM-8x7B,https://huggingface.co/GritLM/GritLM-8x7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 136, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'GritLM/GritLM-8x7B', 'num_gpus': 2, 'quantization_type': None}",22,9,6269
beomi/SOLAR-KOEN-10.8B,https://huggingface.co/beomi/SOLAR-KOEN-10.8B,PyTorch TGI GPU,cc-by-nc-sa-4.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'beomi/SOLAR-KOEN-10.8B', 'num_gpus': 2, 'quantization_type': None}",12,9,2664
m-a-p/OpenCodeInterpreter-CL-7B,https://huggingface.co/m-a-p/OpenCodeInterpreter-CL-7B,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'm-a-p/OpenCodeInterpreter-CL-7B', 'num_gpus': 1, 'quantization_type': None}",9,9,185
PleIAs/OCRonos,https://huggingface.co/PleIAs/OCRonos,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'PleIAs/OCRonos', 'num_gpus': 1, 'quantization_type': None}",9,9,49
unsloth/gemma-7b-it-bnb-4bit,https://huggingface.co/unsloth/gemma-7b-it-bnb-4bit,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'unsloth/gemma-7b-it-bnb-4bit', 'num_gpus': 1, 'quantization_type': 'bitsandbytes'}",9,9,6436
abideen/gemma-7b-openhermes,https://huggingface.co/abideen/gemma-7b-openhermes,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'abideen/gemma-7b-openhermes', 'num_gpus': 1, 'quantization_type': None}",9,9,1472
OPI-PG/Qra-7b,https://huggingface.co/OPI-PG/Qra-7b,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'OPI-PG/Qra-7b', 'num_gpus': 1, 'quantization_type': None}",9,9,10291
piotr-ai/polanka-3b-pretrain-full-v0.4,https://huggingface.co/piotr-ai/polanka-3b-pretrain-full-v0.4,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 9, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'piotr-ai/polanka-3b-pretrain-full-v0.4', 'num_gpus': 1, 'quantization_type': None}",9,9,109
cmcmaster/il_7b,https://huggingface.co/cmcmaster/il_7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cmcmaster/il_7b', 'num_gpus': 1, 'quantization_type': None}",9,9,10
ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1,https://huggingface.co/ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 3, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1', 'num_gpus': 1, 'quantization_type': None}",9,9,141
csebuetnlp/mT5_multilingual_XLSum,https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 2, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'csebuetnlp/mT5_multilingual_XLSum', 'num_gpus': 1, 'quantization_type': None}",221,8,7688
ai-forever/mGPT,https://huggingface.co/ai-forever/mGPT,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 4, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'ai-forever/mGPT', 'num_gpus': 1, 'quantization_type': None}",218,8,72780
bigscience/bloom-560m,https://huggingface.co/bigscience/bloom-560m,PyTorch TGI GPU,bigscience-bloom-rail-1.0,False,False,"{'estimated_memory_in_gigabytes': 2, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'bigscience/bloom-560m', 'num_gpus': 1, 'quantization_type': None}",317,8,297010
TheBloke/Llama-2-13B-chat-GPTQ,https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 19, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/Llama-2-13B-chat-GPTQ', 'num_gpus': 1, 'quantization_type': 'gptq'}",347,8,493634
lmsys/vicuna-13b-v1.5,https://huggingface.co/lmsys/vicuna-13b-v1.5,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'lmsys/vicuna-13b-v1.5', 'num_gpus': 2, 'quantization_type': None}",166,8,77470
PharMolix/BioMedGPT-LM-7B,https://huggingface.co/PharMolix/BioMedGPT-LM-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'PharMolix/BioMedGPT-LM-7B', 'num_gpus': 1, 'quantization_type': None}",48,8,1142
defog/sqlcoder,https://huggingface.co/defog/sqlcoder,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'defog/sqlcoder', 'num_gpus': 2, 'quantization_type': None}",288,8,1512
FreedomIntelligence/AceGPT-13B-chat,https://huggingface.co/FreedomIntelligence/AceGPT-13B-chat,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'FreedomIntelligence/AceGPT-13B-chat', 'num_gpus': 2, 'quantization_type': None}",25,8,945
ToolBench/ToolLLaMA-2-7b-v2,https://huggingface.co/ToolBench/ToolLLaMA-2-7b-v2,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ToolBench/ToolLLaMA-2-7b-v2', 'num_gpus': 1, 'quantization_type': None}",33,8,306
teknium/OpenHermes-2-Mistral-7B,https://huggingface.co/teknium/OpenHermes-2-Mistral-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'teknium/OpenHermes-2-Mistral-7B', 'num_gpus': 1, 'quantization_type': None}",251,8,382990
maritaca-ai/sabia-7b,https://huggingface.co/maritaca-ai/sabia-7b,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'maritaca-ai/sabia-7b', 'num_gpus': 1, 'quantization_type': None}",66,8,3961
jebcarter/psyonic-cetacean-20B,https://huggingface.co/jebcarter/psyonic-cetacean-20B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'jebcarter/psyonic-cetacean-20B', 'num_gpus': 2, 'quantization_type': None}",26,8,2791
mlabonne/Beyonder-4x7B-v2,https://huggingface.co/mlabonne/Beyonder-4x7B-v2,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 78, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'mlabonne/Beyonder-4x7B-v2', 'num_gpus': 1, 'quantization_type': None}",118,8,1995
cloudyu/Yi-34Bx2-MoE-60B,https://huggingface.co/cloudyu/Yi-34Bx2-MoE-60B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 156, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cloudyu/Yi-34Bx2-MoE-60B', 'num_gpus': 2, 'quantization_type': None}",58,8,2587
TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-AWQ,https://huggingface.co/TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-AWQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-AWQ', 'num_gpus': 2, 'quantization_type': 'awq'}",18,8,6617
Qwen/Qwen1.5-4B,https://huggingface.co/Qwen/Qwen1.5-4B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'Qwen/Qwen1.5-4B', 'num_gpus': 1, 'quantization_type': None}",16,8,12753
KatyTheCutie/EstopianMaid-13B,https://huggingface.co/KatyTheCutie/EstopianMaid-13B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'KatyTheCutie/EstopianMaid-13B', 'num_gpus': 2, 'quantization_type': None}",29,8,2217
codellama/CodeLlama-70b-Python-hf,https://huggingface.co/codellama/CodeLlama-70b-Python-hf,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 159, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'codellama/CodeLlama-70b-Python-hf', 'num_gpus': 2, 'quantization_type': None}",95,8,3702
codellama/CodeLlama-70b-Instruct-hf,https://huggingface.co/codellama/CodeLlama-70b-Instruct-hf,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 159, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'codellama/CodeLlama-70b-Instruct-hf', 'num_gpus': 2, 'quantization_type': None}",185,8,9175
jondurbin/bagel-dpo-7b-v0.4,https://huggingface.co/jondurbin/bagel-dpo-7b-v0.4,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'jondurbin/bagel-dpo-7b-v0.4', 'num_gpus': 1, 'quantization_type': None}",16,8,1644
norallm/normistral-7b-warm,https://huggingface.co/norallm/normistral-7b-warm,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'norallm/normistral-7b-warm', 'num_gpus': 1, 'quantization_type': None}",18,8,6925
deepseek-ai/deepseek-math-7b-instruct,https://huggingface.co/deepseek-ai/deepseek-math-7b-instruct,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'deepseek-ai/deepseek-math-7b-instruct', 'num_gpus': 1, 'quantization_type': None}",55,8,16129
vilm/Quyen-v0.1,https://huggingface.co/vilm/Quyen-v0.1,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'vilm/Quyen-v0.1', 'num_gpus': 1, 'quantization_type': None}",11,8,2530
kubernetes-bad/chargen-v2,https://huggingface.co/kubernetes-bad/chargen-v2,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'kubernetes-bad/chargen-v2', 'num_gpus': 1, 'quantization_type': None}",19,8,34
NeverSleep/MiquMaid-v2-70B-DPO,https://huggingface.co/NeverSleep/MiquMaid-v2-70B-DPO,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 158, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'NeverSleep/MiquMaid-v2-70B-DPO', 'num_gpus': 2, 'quantization_type': None}",11,8,163
mobiuslabsgmbh/aanaphi2-v0.1,https://huggingface.co/mobiuslabsgmbh/aanaphi2-v0.1,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 7, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'mobiuslabsgmbh/aanaphi2-v0.1', 'num_gpus': 1, 'quantization_type': None}",15,8,3733
Unbabel/TowerInstruct-7B-v0.2,https://huggingface.co/Unbabel/TowerInstruct-7B-v0.2,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Unbabel/TowerInstruct-7B-v0.2', 'num_gpus': 1, 'quantization_type': None}",8,8,8136
Himitsui/Kaiju-11B,https://huggingface.co/Himitsui/Kaiju-11B,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 46, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Himitsui/Kaiju-11B', 'num_gpus': 2, 'quantization_type': None}",9,8,3046
ISTA-DASLab/Mixtral-8x7B-Instruct-v0_1-AQLM-2Bit-1x16-hf,https://huggingface.co/ISTA-DASLab/Mixtral-8x7B-Instruct-v0_1-AQLM-2Bit-1x16-hf,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 47, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ISTA-DASLab/Mixtral-8x7B-Instruct-v0_1-AQLM-2Bit-1x16-hf', 'num_gpus': 2, 'quantization_type': 'aqlm'}",9,8,2183
Locutusque/Hercules-3.1-Mistral-7B,https://huggingface.co/Locutusque/Hercules-3.1-Mistral-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Locutusque/Hercules-3.1-Mistral-7B', 'num_gpus': 1, 'quantization_type': None}",13,8,2958
bardsai/jaskier-7b-dpo-v6.1,https://huggingface.co/bardsai/jaskier-7b-dpo-v6.1,PyTorch TGI GPU,cc-by-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'bardsai/jaskier-7b-dpo-v6.1', 'num_gpus': 1, 'quantization_type': None}",8,8,3865
abideen/AlphaMonarch-laser,https://huggingface.co/abideen/AlphaMonarch-laser,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'abideen/AlphaMonarch-laser', 'num_gpus': 1, 'quantization_type': None}",8,8,3258
unsloth/gemma-7b-bnb-4bit,https://huggingface.co/unsloth/gemma-7b-bnb-4bit,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'unsloth/gemma-7b-bnb-4bit', 'num_gpus': 1, 'quantization_type': 'bitsandbytes'}",8,8,13641
unsloth/gemma-2b-it-bnb-4bit,https://huggingface.co/unsloth/gemma-2b-it-bnb-4bit,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'unsloth/gemma-2b-it-bnb-4bit', 'num_gpus': 1, 'quantization_type': 'bitsandbytes'}",8,8,4663
unsloth/gemma-7b-it,https://huggingface.co/unsloth/gemma-7b-it,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'unsloth/gemma-7b-it', 'num_gpus': 1, 'quantization_type': None}",8,8,2143
cognitivecomputations/DolphinHermes-120b,https://huggingface.co/cognitivecomputations/DolphinHermes-120b,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 316, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/DolphinHermes-120b', 'num_gpus': 4, 'quantization_type': None}",8,8,1163
USAIL-HKUSTGZ/UrbanKGent-13b,https://huggingface.co/USAIL-HKUSTGZ/UrbanKGent-13b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'USAIL-HKUSTGZ/UrbanKGent-13b', 'num_gpus': 2, 'quantization_type': None}",8,8,30
TIGER-Lab/StructLM-13B,https://huggingface.co/TIGER-Lab/StructLM-13B,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 39, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'TIGER-Lab/StructLM-13B', 'num_gpus': 2, 'quantization_type': None}",8,8,57
m-a-p/ChatMusician-Base,https://huggingface.co/m-a-p/ChatMusician-Base,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'm-a-p/ChatMusician-Base', 'num_gpus': 1, 'quantization_type': None}",8,8,504
0dAI/0dAI-7B,https://huggingface.co/0dAI/0dAI-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': '0dAI/0dAI-7B', 'num_gpus': 1, 'quantization_type': None}",8,8,28
mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-3bit-metaoffload-HQQ,https://huggingface.co/mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-3bit-metaoffload-HQQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-3bit-metaoffload-HQQ', 'num_gpus': 2, 'quantization_type': None}",8,8,31
ajibawa-2023/OpenHermes-2.5-Code-290k-13B,https://huggingface.co/ajibawa-2023/OpenHermes-2.5-Code-290k-13B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ajibawa-2023/OpenHermes-2.5-Code-290k-13B', 'num_gpus': 2, 'quantization_type': None}",8,8,2240
KatyTheCutie/LemonadeRP-4.5.3,https://huggingface.co/KatyTheCutie/LemonadeRP-4.5.3,PyTorch TGI GPU,cc-by-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'KatyTheCutie/LemonadeRP-4.5.3', 'num_gpus': 1, 'quantization_type': None}",8,8,1306
Locutusque/Hyperion-1.5-Mistral-7B,https://huggingface.co/Locutusque/Hyperion-1.5-Mistral-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Locutusque/Hyperion-1.5-Mistral-7B', 'num_gpus': 1, 'quantization_type': None}",8,8,1845
hydra-project/ChatHercules-2.5-Mistral-7B,https://huggingface.co/hydra-project/ChatHercules-2.5-Mistral-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'hydra-project/ChatHercules-2.5-Mistral-7B', 'num_gpus': 1, 'quantization_type': None}",8,8,1704
maywell/KoMultiGen-General,https://huggingface.co/maywell/KoMultiGen-General,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'maywell/KoMultiGen-General', 'num_gpus': 2, 'quantization_type': None}",8,8,18
Rakuten/RakutenAI-7B-instruct,https://huggingface.co/Rakuten/RakutenAI-7B-instruct,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Rakuten/RakutenAI-7B-instruct', 'num_gpus': 1, 'quantization_type': None}",8,8,26
flax-community/t5-recipe-generation,https://huggingface.co/flax-community/t5-recipe-generation,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Rakuten/RakutenAI-7B-instruct', 'num_gpus': 1, 'quantization_type': None}",41,7,55286
microsoft/DialoGPT-large,https://huggingface.co/microsoft/DialoGPT-large,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 3, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'microsoft/DialoGPT-large', 'num_gpus': 1, 'quantization_type': None}",247,7,199412
stanford-crfm/BioMedLM,https://huggingface.co/stanford-crfm/BioMedLM,PyTorch TGI GPU,bigscience-bloom-rail-1.0,False,False,"{'estimated_memory_in_gigabytes': 7, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'stanford-crfm/BioMedLM', 'num_gpus': 1, 'quantization_type': None}",292,7,3124
FlagAlpha/Llama2-Chinese-13b-Chat,https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'FlagAlpha/Llama2-Chinese-13b-Chat', 'num_gpus': 2, 'quantization_type': None}",263,7,4611
WizardLM/WizardLM-70B-V1.0,https://huggingface.co/WizardLM/WizardLM-70B-V1.0,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 159, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'WizardLM/WizardLM-70B-V1.0', 'num_gpus': 2, 'quantization_type': None}",222,7,10705
codellama/CodeLlama-13b-hf,https://huggingface.co/codellama/CodeLlama-13b-hf,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 39, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'codellama/CodeLlama-13b-hf', 'num_gpus': 2, 'quantization_type': None}",86,7,17392
PygmalionAI/pygmalion-2-13b,https://huggingface.co/PygmalionAI/pygmalion-2-13b,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 38, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'PygmalionAI/pygmalion-2-13b', 'num_gpus': 2, 'quantization_type': None}",68,7,6423
EleutherAI/llemma_7b,https://huggingface.co/EleutherAI/llemma_7b,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 21, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'EleutherAI/llemma_7b', 'num_gpus': 1, 'quantization_type': None}",73,7,56559
jphme/em_german_leo_mistral,https://huggingface.co/jphme/em_german_leo_mistral,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'jphme/em_german_leo_mistral', 'num_gpus': 1, 'quantization_type': None}",60,7,5562
Falconsai/medical_summarization,https://huggingface.co/Falconsai/medical_summarization,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'jphme/em_german_leo_mistral', 'num_gpus': 1, 'quantization_type': None}",59,7,1801
flozi00/Mistral-7B-german-assistant-v4,https://huggingface.co/flozi00/Mistral-7B-german-assistant-v4,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'flozi00/Mistral-7B-german-assistant-v4', 'num_gpus': 1, 'quantization_type': None}",9,7,337
QizhiPei/biot5-base,https://huggingface.co/QizhiPei/biot5-base,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 1, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'QizhiPei/biot5-base', 'num_gpus': 1, 'quantization_type': None}",7,7,181
cognitivecomputations/dolphin-2.2.1-mistral-7b,https://huggingface.co/cognitivecomputations/dolphin-2.2.1-mistral-7b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/dolphin-2.2.1-mistral-7b', 'num_gpus': 1, 'quantization_type': None}",171,7,67932
cyberagent/calm2-7b-chat,https://huggingface.co/cyberagent/calm2-7b-chat,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cyberagent/calm2-7b-chat', 'num_gpus': 1, 'quantization_type': None}",66,7,15156
gorilla-llm/gorilla-openfunctions-v1,https://huggingface.co/gorilla-llm/gorilla-openfunctions-v1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'gorilla-llm/gorilla-openfunctions-v1', 'num_gpus': 1, 'quantization_type': None}",92,7,600
SUSTech/SUS-Chat-34B,https://huggingface.co/SUSTech/SUS-Chat-34B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'SUSTech/SUS-Chat-34B', 'num_gpus': 1, 'quantization_type': None}",110,7,4033
riotu-lab/ArabianGPT-01B,https://huggingface.co/riotu-lab/ArabianGPT-01B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 1, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'riotu-lab/ArabianGPT-01B', 'num_gpus': 1, 'quantization_type': None}",7,7,227
unsloth/mistral-7b-bnb-4bit,https://huggingface.co/unsloth/mistral-7b-bnb-4bit,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'unsloth/mistral-7b-bnb-4bit', 'num_gpus': 1, 'quantization_type': 'bitsandbytes'}",17,7,52028
Vikhrmodels/Vikhr-7b-0.1,https://huggingface.co/Vikhrmodels/Vikhr-7b-0.1,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Vikhrmodels/Vikhr-7b-0.1', 'num_gpus': 1, 'quantization_type': None}",45,7,439
nsfwthrowitaway69/Venus-120b-v1.2,https://huggingface.co/nsfwthrowitaway69/Venus-120b-v1.2,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 316, 'gcp_instance': 'a2-ultragpu-4g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'nsfwthrowitaway69/Venus-120b-v1.2', 'num_gpus': 4, 'quantization_type': None}",38,7,53
ahxt/LiteLlama-460M-1T,https://huggingface.co/ahxt/LiteLlama-460M-1T,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 2, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'ahxt/LiteLlama-460M-1T', 'num_gpus': 1, 'quantization_type': None}",152,7,42742
meetkai/functionary-medium-v2.2,https://huggingface.co/meetkai/functionary-medium-v2.2,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 130, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'meetkai/functionary-medium-v2.2', 'num_gpus': 2, 'quantization_type': None}",23,7,1178
cognitivecomputations/TinyDolphin-2.8-1.1b,https://huggingface.co/cognitivecomputations/TinyDolphin-2.8-1.1b,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/TinyDolphin-2.8-1.1b', 'num_gpus': 1, 'quantization_type': None}",28,7,5499
motherduckdb/DuckDB-NSQL-7B-v0.1,https://huggingface.co/motherduckdb/DuckDB-NSQL-7B-v0.1,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'motherduckdb/DuckDB-NSQL-7B-v0.1', 'num_gpus': 1, 'quantization_type': None}",45,7,199
cfahlgren1/natural-functions,https://huggingface.co/cfahlgren1/natural-functions,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cfahlgren1/natural-functions', 'num_gpus': 1, 'quantization_type': None}",31,7,155
sambanovasystems/BLOOMChat-176B-v2,https://huggingface.co/sambanovasystems/BLOOMChat-176B-v2,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 411, 'gcp_instance': 'a2-ultragpu-8g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sambanovasystems/BLOOMChat-176B-v2', 'num_gpus': 8, 'quantization_type': None}",12,7,185
sophosympatheia/Midnight-Rose-70B-v2.0.3,https://huggingface.co/sophosympatheia/Midnight-Rose-70B-v2.0.3,PyTorch TGI GPU,llama2,False,False,"{'estimated_memory_in_gigabytes': 159, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'sophosympatheia/Midnight-Rose-70B-v2.0.3', 'num_gpus': 2, 'quantization_type': None}",10,7,1467
Nitral-AI/Kunocchini-7b-128k-test,https://huggingface.co/Nitral-AI/Kunocchini-7b-128k-test,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Nitral-AI/Kunocchini-7b-128k-test', 'num_gpus': 1, 'quantization_type': None}",12,7,2416
BiMediX/BiMediX-Eng,https://huggingface.co/BiMediX/BiMediX-Eng,PyTorch TGI GPU,cc-by-nc-sa-4.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'BiMediX/BiMediX-Eng', 'num_gpus': 2, 'quantization_type': None}",7,7,56
utrobinmv/t5_summary_en_ru_zh_base_2048,https://huggingface.co/utrobinmv/t5_summary_en_ru_zh_base_2048,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'BiMediX/BiMediX-Eng', 'num_gpus': 2, 'quantization_type': None}",7,7,1430
unsloth/gemma-2b-bnb-4bit,https://huggingface.co/unsloth/gemma-2b-bnb-4bit,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'unsloth/gemma-2b-bnb-4bit', 'num_gpus': 1, 'quantization_type': 'bitsandbytes'}",7,7,6483
Minami-su/Qwen1.5-7B-Chat_mistral,https://huggingface.co/Minami-su/Qwen1.5-7B-Chat_mistral,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'Minami-su/Qwen1.5-7B-Chat_mistral', 'num_gpus': 1, 'quantization_type': None}",7,7,2988
weqweasdas/RM-Gemma-2B,https://huggingface.co/weqweasdas/RM-Gemma-2B,PyTorch TGI GPU,N/A,False,False,"{'estimated_memory_in_gigabytes': 7, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'weqweasdas/RM-Gemma-2B', 'num_gpus': 1, 'quantization_type': None}",7,7,348
mlabonne/Gemmalpaca-7B,https://huggingface.co/mlabonne/Gemmalpaca-7B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'mlabonne/Gemmalpaca-7B', 'num_gpus': 1, 'quantization_type': None}",7,7,59
FuseAI/OpenChat-3.5-7B-Solar,https://huggingface.co/FuseAI/OpenChat-3.5-7B-Solar,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'FuseAI/OpenChat-3.5-7B-Solar', 'num_gpus': 1, 'quantization_type': None}",7,7,1828
MaziyarPanahi/Mistral-7B-Instruct-Aya-101,https://huggingface.co/MaziyarPanahi/Mistral-7B-Instruct-Aya-101,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'MaziyarPanahi/Mistral-7B-Instruct-Aya-101', 'num_gpus': 1, 'quantization_type': None}",7,7,1254
sail/Sailor-0.5B,https://huggingface.co/sail/Sailor-0.5B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'sail/Sailor-0.5B', 'num_gpus': 1, 'quantization_type': None}",7,7,9168
mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-2bitgs8-metaoffload-HQQ,https://huggingface.co/mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-2bitgs8-metaoffload-HQQ,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 135, 'gcp_instance': 'a2-ultragpu-2g', 'max_batch_prefill_tokens': 16384, 'max_input_length': 8000, 'max_total_tokens': 16384, 'model_id': 'mobiuslabsgmbh/Mixtral-8x7B-Instruct-v0.1-hf-attn-4bit-moe-2bitgs8-metaoffload-HQQ', 'num_gpus': 2, 'quantization_type': None}",7,7,24
hydra-project/OpenHercules-2.5-Mistral-7B,https://huggingface.co/hydra-project/OpenHercules-2.5-Mistral-7B,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'hydra-project/OpenHercules-2.5-Mistral-7B', 'num_gpus': 1, 'quantization_type': None}",7,7,1116
ChaoticNeutrals/Eris_Remix_7B,https://huggingface.co/ChaoticNeutrals/Eris_Remix_7B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ChaoticNeutrals/Eris_Remix_7B', 'num_gpus': 1, 'quantization_type': None}",7,7,1723
cognitivecomputations/dolphincoder-starcoder2-7b,https://huggingface.co/cognitivecomputations/dolphincoder-starcoder2-7b,PyTorch TGI GPU,bigcode-openrail-m,False,False,"{'estimated_memory_in_gigabytes': 22, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 6144, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'cognitivecomputations/dolphincoder-starcoder2-7b', 'num_gpus': 1, 'quantization_type': None}",7,7,56
ChaoticNeutrals/BuRP_7B,https://huggingface.co/ChaoticNeutrals/BuRP_7B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'ChaoticNeutrals/BuRP_7B', 'num_gpus': 1, 'quantization_type': None}",7,7,58
grimjim/kukulemon-7B,https://huggingface.co/grimjim/kukulemon-7B,PyTorch TGI GPU,cc-by-nc-4.0,False,False,"{'estimated_memory_in_gigabytes': 23, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 8192, 'max_input_length': 3072, 'max_total_tokens': 4096, 'model_id': 'grimjim/kukulemon-7B', 'num_gpus': 1, 'quantization_type': None}",7,7,941
Locutusque/Hyperion-3.0-Yi-34B,https://huggingface.co/Locutusque/Hyperion-3.0-Yi-34B,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 79, 'gcp_instance': 'a2-ultragpu-1g', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'Locutusque/Hyperion-3.0-Yi-34B', 'num_gpus': 1, 'quantization_type': None}",7,7,182
Telugu-LLM-Labs/Indic-gemma-2b-finetuned-sft-Navarasa-2.0,https://huggingface.co/Telugu-LLM-Labs/Indic-gemma-2b-finetuned-sft-Navarasa-2.0,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 16384, 'max_input_length': 4096, 'max_total_tokens': 8192, 'model_id': 'Telugu-LLM-Labs/Indic-gemma-2b-finetuned-sft-Navarasa-2.0', 'num_gpus': 1, 'quantization_type': None}",7,7,81
openai-community/gpt2-medium,https://huggingface.co/openai-community/gpt2-medium,PyTorch TGI GPU,mit,False,False,"{'estimated_memory_in_gigabytes': 2, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 800, 'max_total_tokens': 1024, 'model_id': 'openai-community/gpt2-medium', 'num_gpus': 1, 'quantization_type': None}",111,6,356604
google/mt5-base,https://huggingface.co/google/mt5-base,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 2, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'google/mt5-base', 'num_gpus': 1, 'quantization_type': None}",152,6,473324
vennify/t5-base-grammar-correction,https://huggingface.co/vennify/t5-base-grammar-correction,PyTorch TGI GPU,cc-by-nc-sa-4.0,False,False,"{'estimated_memory_in_gigabytes': 2, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'google/mt5-base', 'num_gpus': 1, 'quantization_type': None}",112,6,4322084
bigscience/bloomz-7b1,https://huggingface.co/bigscience/bloomz-7b1,PyTorch TGI GPU,bigscience-bloom-rail-1.0,False,False,"{'estimated_memory_in_gigabytes': 17, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'bigscience/bloomz-7b1', 'num_gpus': 1, 'quantization_type': None}",126,6,69907
OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5,https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5,PyTorch TGI GPU,apache-2.0,False,False,"{'estimated_memory_in_gigabytes': 29, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5', 'num_gpus': 2, 'quantization_type': None}",354,6,5260
huggyllama/llama-7b,https://huggingface.co/huggyllama/llama-7b,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'huggyllama/llama-7b', 'num_gpus': 1, 'quantization_type': None}",248,6,124607
cognitivecomputations/Wizard-Vicuna-13B-Uncensored,https://huggingface.co/cognitivecomputations/Wizard-Vicuna-13B-Uncensored,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 32, 'gcp_instance': 'g2-standard-24', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'cognitivecomputations/Wizard-Vicuna-13B-Uncensored', 'num_gpus': 2, 'quantization_type': None}",268,6,3337
cognitivecomputations/Wizard-Vicuna-7B-Uncensored,https://huggingface.co/cognitivecomputations/Wizard-Vicuna-7B-Uncensored,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 16, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'cognitivecomputations/Wizard-Vicuna-7B-Uncensored', 'num_gpus': 1, 'quantization_type': None}",81,6,2429
TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GPTQ,https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GPTQ,PyTorch TGI GPU,other,False,False,"{'estimated_memory_in_gigabytes': 13, 'gcp_instance': 'g2-standard-4', 'max_batch_prefill_tokens': 2048, 'max_input_length': 1512, 'max_total_tokens': 2048, 'model_id': 'TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GPTQ', 'num_gpus': 1, 'quantization_type': 'gptq'}",121,6,202
