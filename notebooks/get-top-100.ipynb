{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r \n",
    "from recommender.main import get_memory_per_model_and_tgi, get_tgi_memory, get_quantization_type, get_max_prompt_length\n",
    "\n",
    "headers = {\n",
    "  \"Authorization\": \"Bearer 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\"\n",
    "}\n",
    "\n",
    "def check_for_gate(model_id):\n",
    "  url = f\"https://huggingface.co/api/models/{model_id}\"\n",
    "  response = r.get(url).json()\n",
    "  error = response.get(\"error\",None)\n",
    "  if error and \"gate\" in error:\n",
    "    return True\n",
    "  \n",
    "  return False\n",
    "\n",
    "\n",
    "def get_tgi_models_and_parse(limit=250,type=\"likes30d\",filter=\"text-generation-inference\"):\n",
    "  url=f\"https://huggingface.co/api/models?sort={type}&direction=-1&filter={filter}&limit={limit}\"\n",
    "  # url = \"https://huggingface.co/api/models/meta-llama/Llama-2-7b-chat-hf\"\n",
    "  # response = [r.get(url, headers=headers).json()]\n",
    "  response = r.get(url, headers=headers).json()\n",
    "  # map, filter list to remove gguf \n",
    "  filtered_models=[]\n",
    "  for model in response:\n",
    "    try:\n",
    "      # backlist models which leads to crashes on my mac\n",
    "      if model[\"id\"] in [\"LargeWorldModel/LWM-Text-Chat-1M\",\"LargeWorldModel/LWM-Text-1M\",\"LargeWorldModel/LWM-Text-512K\", \"LargeWorldModel/LWM-Chat-512K\"]:\n",
    "        continue\n",
    "      \n",
    "      # remove gguf models\n",
    "      if \"gguf\" in model[\"tags\"]:\n",
    "        continue\n",
    "      \n",
    "      # check for gate\n",
    "      gated = check_for_gate(model[\"id\"])    \n",
    "      \n",
    "      # get license \n",
    "      license_value = next((tag.split(':', 1)[1] for tag in model[\"tags\"] if tag.startswith('license:')), \"N/A\")\n",
    "      \n",
    "      # model size\n",
    "      if not gated:\n",
    "        # remove quantized models for now\n",
    "        quantization_type = get_quantization_type(model_id=model[\"id\"])\n",
    "        if quantization_type:\n",
    "          continue\n",
    "        \n",
    "        memory = get_memory_per_model_and_tgi(model[\"id\"],8192,\"float16\")\n",
    "        memory = memory['real_memory_in_gigabytes']\n",
    "      else:\n",
    "        memory=-1\n",
    "            \n",
    "      # model size   \n",
    "      filtered_models.append({\n",
    "        \"model_id\": model[\"id\"],\n",
    "        \"url\": f\"https://huggingface.co/{model['id']}\",\n",
    "        \"cotaniner\": \"PyTorch TGI GPU\",\n",
    "        \"approx. min. required memory\": f\"{memory}GB\",\n",
    "        \"license\": license_value,\n",
    "        \"gated\": gated,\n",
    "        \"private\": model[\"private\"],\n",
    "        \"likes\": model[\"likes\"],\n",
    "        \"likes30d\": model[\"likes30d\"],\n",
    "        \"downloads\": model[\"downloads\"],\n",
    "      })\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      print(f\"Error parsing model {model['id']}\")\n",
    "      continue\n",
    "  return filtered_models\n",
    "\n",
    "def get_emb_models_and_parse(limit=25,type=\"likes30d\",filter=\"sentence-transformers\"):\n",
    "  url=f\"https://huggingface.co/api/models?sort={type}&direction=-1&filter={filter}&limit={limit}\"\n",
    "  response = r.get(url, headers=headers).json()\n",
    "  # supported TEI architectures\n",
    "  architectures = [\"bert\", \"roberta\", \"xlm-roberta\",\"nomic_bert\"]\n",
    "  # map, filter list to remove gguf \n",
    "  filtered_models=[]\n",
    "  for model in response:\n",
    "    try:\n",
    "      # backlist models which leads to crashes on my mac\n",
    "      if model[\"id\"] in []:\n",
    "        continue\n",
    "      # filter TEI supported architectures\n",
    "      if not any(architecture in model[\"tags\"] for architecture in architectures):\n",
    "        continue\n",
    "      \n",
    "      # get license \n",
    "      license_value = next((tag.split(':', 1)[1] for tag in model[\"tags\"] if tag.startswith('license:')), \"N/A\")\n",
    "      \n",
    "      # check for gate\n",
    "      gated = check_for_gate(model[\"id\"])    \n",
    "                  \n",
    "      # model size   \n",
    "      filtered_models.append({\n",
    "        \"model_id\": model[\"id\"],\n",
    "        \"url\": f\"https://huggingface.co/{model['id']}\",\n",
    "        \"cotaniner\": \"PyTorch TEI CPU/GPU\",\n",
    "        \"license\": license_value,\n",
    "        \"gated\": gated,\n",
    "        \"private\": model[\"private\"],\n",
    "        \"likes\": model[\"likes\"],\n",
    "        \"likes30d\": model[\"likes30d\"],\n",
    "        \"downloads\": model[\"downloads\"],\n",
    "      })\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      print(f\"Error parsing model {model['id']}\")\n",
    "      continue\n",
    "  return filtered_models  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained config for `mistralai/Mixtral-8x7B-Instruct-v0.1` from `transformers`...\n",
      "Loading pretrained config for `bigcode/starcoder2-15b` from `transformers`...\n",
      "Loading pretrained config for `BioMistral/BioMistral-7B` from `transformers`...\n",
      "Loading pretrained config for `mistralai/Mistral-7B-Instruct-v0.2` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Genstruct-7B` from `transformers`...\n",
      "Loading pretrained config for `CohereForAI/aya-101` from `transformers`...\n",
      "Loading pretrained config for `microsoft/phi-2` from `transformers`...\n",
      "Loading pretrained config for `mistralai/Mistral-7B-v0.1` from `transformers`...\n",
      "Loading pretrained config for `01-ai/Yi-9B` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Hermes-2-Pro-Mistral-7B` from `transformers`...\n",
      "Loading pretrained config for `abacusai/Smaug-72B-v0.1` from `transformers`...\n",
      "Loading pretrained config for `mistralai/Mixtral-8x7B-v0.1` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Nous-Hermes-2-Mistral-7B-DPO` from `transformers`...\n",
      "Loading pretrained config for `bigcode/starcoder2-7b` from `transformers`...\n",
      "Loading pretrained config for `mlabonne/AlphaMonarch-7B` from `transformers`...\n",
      "Loading pretrained config for `m-a-p/OpenCodeInterpreter-DS-6.7B` from `transformers`...\n",
      "Loading pretrained config for `HuggingFaceH4/zephyr-7b-gemma-v0.1` from `transformers`...\n",
      "Loading pretrained config for `HuggingFaceH4/zephyr-7b-beta` from `transformers`...\n",
      "Loading pretrained config for `bigcode/starcoder2-3b` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO` from `transformers`...\n",
      "Loading pretrained config for `HuggingFaceTB/cosmo-1b` from `transformers`...\n",
      "Loading pretrained config for `bigscience/bloom` from `transformers`...\n",
      "Loading pretrained config for `fireworks-ai/firefunction-v1` from `transformers`...\n",
      "Loading pretrained config for `Qwen/Qwen1.5-72B-Chat` from `transformers`...\n",
      "Loading pretrained config for `ibm/merlinite-7b` from `transformers`...\n",
      "Loading pretrained config for `m-a-p/ChatMusician` from `transformers`...\n",
      "Loading pretrained config for `abacaj/phi-2-super` from `transformers`...\n",
      "Loading pretrained config for `teknium/OpenHermes-2.5-Mistral-7B` from `transformers`...\n",
      "Loading pretrained config for `gorilla-llm/gorilla-openfunctions-v2` from `transformers`...\n",
      "Loading pretrained config for `openai-community/gpt2` from `transformers`...\n",
      "Loading pretrained config for `openchat/openchat-3.5-0106` from `transformers`...\n",
      "Loading pretrained config for `ibm/labradorite-13b` from `transformers`...\n",
      "Loading pretrained config for `TencentARC/Mistral_Pro_8B_v0.1` from `transformers`...\n",
      "Loading pretrained config for `01-ai/Yi-34B-200K` from `transformers`...\n",
      "Loading pretrained config for `WhiteRabbitNeo/WhiteRabbitNeo-13B-v1` from `transformers`...\n",
      "Loading pretrained config for `mistralai/Mistral-7B-Instruct-v0.1` from `transformers`...\n",
      "Loading pretrained config for `cognitivecomputations/dolphin-2.5-mixtral-8x7b` from `transformers`...\n",
      "Loading pretrained config for `abacusai/Liberated-Qwen1.5-72B` from `transformers`...\n",
      "Loading pretrained config for `Phind/Phind-CodeLlama-34B-v2` from `transformers`...\n",
      "Loading pretrained config for `m-a-p/OpenCodeInterpreter-DS-33B` from `transformers`...\n",
      "Loading pretrained config for `yam-peleg/Experiment26-7B` from `transformers`...\n",
      "Loading pretrained config for `PipableAI/pip-sql-1.3b` from `transformers`...\n",
      "Loading pretrained config for `deepseek-ai/deepseek-coder-33b-instruct` from `transformers`...\n",
      "Loading pretrained config for `TinyLlama/TinyLlama-1.1B-Chat-v1.0` from `transformers`...\n",
      "Loading pretrained config for `Qwen/Qwen1.5-7B-Chat` from `transformers`...\n",
      "Loading pretrained config for `BatsResearch/bonito-v1` from `transformers`...\n",
      "Loading pretrained config for `HuggingFaceH4/starchat2-15b-v0.1` from `transformers`...\n",
      "Loading pretrained config for `FuseAI/FuseChat-7B-VaRM` from `transformers`...\n",
      "Loading pretrained config for `wolfram/miquliz-120b-v2.0` from `transformers`...\n",
      "Loading pretrained config for `Crystalcareai/Qwen1.5-8x7b` from `transformers`...\n",
      "Loading pretrained config for `Qwen/Qwen1.5-0.5B` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Russian-Chat` from `transformers`...\n",
      "Loading pretrained config for `cognitivecomputations/dolphincoder-starcoder2-15b` from `transformers`...\n",
      "Loading pretrained config for `INSAIT-Institute/BgGPT-7B-Instruct-v0.1` from `transformers`...\n",
      "Loading pretrained config for `deepseek-ai/deepseek-coder-6.7b-instruct` from `transformers`...\n",
      "Loading pretrained config for `intfloat/e5-mistral-7b-instruct` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Arabic-Chat` from `transformers`...\n",
      "Loading pretrained config for `GritLM/GritLM-7B` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Turkish-Chat` from `transformers`...\n",
      "Loading pretrained config for `google/flan-t5-base` from `transformers`...\n",
      "Loading pretrained config for `berkeley-nest/Starling-LM-7B-alpha` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Arabic-Base` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Turkish-Base` from `transformers`...\n",
      "Loading pretrained config for `google/flan-t5-large` from `transformers`...\n",
      "Loading pretrained config for `AetherResearch/Cerebrum-1.0-7b` from `transformers`...\n",
      "Loading pretrained config for `Sao10K/Fimbulvetr-11B-v2` from `transformers`...\n",
      "Loading pretrained config for `WhiteRabbitNeo/WhiteRabbitNeo-33B-v1.5` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Hungarian-Chat` from `transformers`...\n",
      "Loading pretrained config for `01-ai/Yi-34B` from `transformers`...\n",
      "Loading pretrained config for `upstage/SOLAR-10.7B-Instruct-v1.0` from `transformers`...\n",
      "Loading pretrained config for `Qwen/Qwen1.5-14B-Chat` from `transformers`...\n",
      "Loading pretrained config for `openchat/openchat_3.5` from `transformers`...\n",
      "Loading pretrained config for `01-ai/Yi-34B-Chat` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Bulgarian-Chat` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Japanese-Chat` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Thai-Chat` from `transformers`...\n",
      "Loading pretrained config for `yam-peleg/Hebrew-Gemma-11B` from `transformers`...\n",
      "Loading pretrained config for `openchat/openchat-3.5-0106-gemma` from `transformers`...\n",
      "Loading pretrained config for `georgesung/llama2_7b_chat_uncensored` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Hungarian-Base` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Russian-Base` from `transformers`...\n",
      "Loading pretrained config for `Weyaxi/Einstein-v4-7B` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Thai-Base` from `transformers`...\n",
      "Loading pretrained config for `Open-Orca/Mistral-7B-OpenOrca` from `transformers`...\n",
      "Loading pretrained config for `Trendyol/Trendyol-LLM-7b-chat-v0.1` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Slovenian-Chat` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Serbian-Chat` from `transformers`...\n",
      "Loading pretrained config for `WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a` from `transformers`...\n",
      "Loading pretrained config for `l3utterfly/mistral-7b-v0.1-layla-v4` from `transformers`...\n",
      "Loading pretrained config for `abacusai/bigstral-12b-32k` from `transformers`...\n",
      "Loading pretrained config for `senseable/WestLake-7B-v2` from `transformers`...\n",
      "Loading pretrained config for `codellama/CodeLlama-70b-hf` from `transformers`...\n",
      "Loading pretrained config for `defog/sqlcoder-70b-alpha` from `transformers`...\n",
      "Loading pretrained config for `MBZUAI/MobiLlama-05B` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Serbian-Base` from `transformers`...\n",
      "Loading pretrained config for `152334H/miqu-1-70b-sf` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Bulgarian-Base` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Japanese-Base` from `transformers`...\n",
      "Loading pretrained config for `sambanovasystems/SambaLingo-Slovenian-Base` from `transformers`...\n",
      "Loading pretrained config for `sophosympatheia/Midnight-Miqu-70B-v1.0` from `transformers`...\n",
      "Loading pretrained config for `lmsys/vicuna-7b-v1.5` from `transformers`...\n",
      "Loading pretrained config for `microsoft/Orca-2-13b` from `transformers`...\n",
      "Loading pretrained config for `cognitivecomputations/dolphin-2.6-mixtral-8x7b` from `transformers`...\n",
      "Loading pretrained config for `abacusai/TheProfessor-155b` from `transformers`...\n",
      "Loading pretrained config for `CausalLM/34b-beta` from `transformers`...\n",
      "Loading pretrained config for `bardsai/jaskier-7b-dpo-v5.6` from `transformers`...\n",
      "Loading pretrained config for `Gustavosta/MagicPrompt-Stable-Diffusion` from `transformers`...\n",
      "Loading pretrained config for `google/flan-t5-xxl` from `transformers`...\n",
      "Loading pretrained config for `snorkelai/Snorkel-Mistral-PairRM-DPO` from `transformers`...\n",
      "Loading pretrained config for `yanolja/EEVE-Korean-10.8B-v1.0` from `transformers`...\n",
      "Loading pretrained config for `Equall/Saul-Instruct-v1` from `transformers`...\n",
      "Loading pretrained config for `m-a-p/OpenCodeInterpreter-CL-70B` from `transformers`...\n",
      "Loading pretrained config for `gordicaleksa/YugoGPT` from `transformers`...\n",
      "Loading pretrained config for `OPI-PG/Qra-13b` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Nous-Capybara-34B` from `transformers`...\n",
      "Loading pretrained config for `Nexusflow/NexusRaven-V2-13B` from `transformers`...\n",
      "DREX-Institute/2.5D_ANIME_NSFW does not appear to have a file named config.json. Checkout 'https://huggingface.co/DREX-Institute/2.5D_ANIME_NSFW/main' for available files.\n",
      "Error parsing model DREX-Institute/2.5D_ANIME_NSFW\n",
      "Loading pretrained config for `tiiuae/falcon-7b` from `transformers`...\n",
      "Loading pretrained config for `microsoft/phi-1_5` from `transformers`...\n",
      "Loading pretrained config for `Falconsai/text_summarization` from `transformers`...\n",
      "Loading pretrained config for `upstage/SOLAR-10.7B-v1.0` from `transformers`...\n",
      "Loading pretrained config for `GritLM/GritLM-8x7B` from `transformers`...\n",
      "Loading pretrained config for `roborovski/superprompt-v1` from `transformers`...\n",
      "Loading pretrained config for `sail/Sailor-7B` from `transformers`...\n",
      "Loading pretrained config for `HuggingFaceH4/zephyr-7b-alpha` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Nous-Hermes-2-Yi-34B` from `transformers`...\n",
      "Loading pretrained config for `Qwen/Qwen1.5-0.5B-Chat` from `transformers`...\n",
      "Loading pretrained config for `dreamgen/opus-v1.2-7b` from `transformers`...\n",
      "Loading pretrained config for `beomi/gemma-ko-7b` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Nous-Hermes-2-SOLAR-10.7B` from `transformers`...\n",
      "Loading pretrained config for `MediaTek-Research/Breeze-7B-Instruct-v0_1` from `transformers`...\n",
      "Loading pretrained config for `codefuse-ai/CodeFuse-DeepSeek-33B` from `transformers`...\n",
      "Loading pretrained config for `jondurbin/airoboros-34b-3.2` from `transformers`...\n",
      "Loading pretrained config for `cognitivecomputations/WizardLM-7B-Uncensored` from `transformers`...\n",
      "Loading pretrained config for `TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T` from `transformers`...\n",
      "Loading pretrained config for `cognitivecomputations/dolphin-2.7-mixtral-8x7b` from `transformers`...\n",
      "Loading pretrained config for `riotu-lab/ArabianGPT-03B` from `transformers`...\n",
      "Loading pretrained config for `Qwen/Qwen1.5-72B` from `transformers`...\n",
      "Loading pretrained config for `brucethemoose/Yi-34B-200K-RPMerge` from `transformers`...\n",
      "Loading pretrained config for `maywell/kiqu-70b` from `transformers`...\n",
      "Loading pretrained config for `MBZUAI/MobiLlama-1B-Chat` from `transformers`...\n",
      "Loading pretrained config for `ytu-ce-cosmos/turkish-gpt2-large` from `transformers`...\n",
      "Loading pretrained config for `occiglot/occiglot-7b-eu5` from `transformers`...\n",
      "Loading pretrained config for `amazon/chronos-t5-large` from `transformers`...\n",
      "Loading pretrained config for `google-t5/t5-base` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Yarn-Mistral-7b-128k` from `transformers`...\n",
      "Loading pretrained config for `01-ai/Yi-6B-Chat` from `transformers`...\n",
      "Loading pretrained config for `utrobinmv/t5_translate_en_ru_zh_large_1024` from `transformers`...\n",
      "Loading pretrained config for `deepseek-ai/deepseek-coder-7b-instruct-v1.5` from `transformers`...\n",
      "Loading pretrained config for `chatdb/natural-sql-7b` from `transformers`...\n",
      "Loading pretrained config for `Equall/Saul-Base` from `transformers`...\n",
      "Loading pretrained config for `Vikhrmodels/Vikhr-7B-instruct_0.2` from `transformers`...\n",
      "Loading pretrained config for `IlyaGusev/saiga_gemma_9b` from `transformers`...\n",
      "Loading pretrained config for `wolfram/miqu-1-103b` from `transformers`...\n",
      "Loading pretrained config for `cognitivecomputations/dolphin-2.8-experiment26-7b` from `transformers`...\n",
      "Loading pretrained config for `Trendyol/Trendyol-LLM-7b-chat-v1.0` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Llama-2-7b-hf` from `transformers`...\n",
      "Loading pretrained config for `NousResearch/Llama-2-7b-chat-hf` from `transformers`...\n",
      "Loading pretrained config for `codellama/CodeLlama-7b-hf` from `transformers`...\n",
      "Loading pretrained config for `AdaptLLM/finance-LLM` from `transformers`...\n",
      "Loading pretrained config for `AdaptLLM/finance-chat` from `transformers`...\n",
      "Loading pretrained config for `SanjiWatsuki/Silicon-Maid-7B` from `transformers`...\n",
      "Loading pretrained config for `segolilylabs/Lily-Cybersecurity-7B-v0.2` from `transformers`...\n",
      "Loading pretrained config for `SanjiWatsuki/Kunoichi-DPO-v2-7B` from `transformers`...\n",
      "Loading pretrained config for `h2oai/h2o-danube-1.8b-chat` from `transformers`...\n",
      "Loading pretrained config for `LargeWorldModel/LWM-Text-Chat-128K` from `transformers`...\n",
      "Loading pretrained config for `m-a-p/OpenCodeInterpreter-DS-1.3B` from `transformers`...\n",
      "Loading pretrained config for `yam-peleg/Hebrew-Gemma-11B-Instruct` from `transformers`...\n",
      "Loading pretrained config for `saltlux/luxia-21.4b-alignment-v1.0` from `transformers`...\n",
      "Loading pretrained config for `distilbert/distilgpt2` from `transformers`...\n",
      "Loading pretrained config for `openai-community/gpt2-large` from `transformers`...\n",
      "Loading pretrained config for `openai-community/gpt2-xl` from `transformers`...\n",
      "Loading pretrained config for `google-t5/t5-small` from `transformers`...\n",
      "Loading pretrained config for `KoboldAI/OPT-13B-Erebus` from `transformers`...\n",
      "Loading pretrained config for `cognitivecomputations/WizardLM-13B-Uncensored` from `transformers`...\n",
      "Loading pretrained config for `codellama/CodeLlama-7b-Instruct-hf` from `transformers`...\n",
      "Loading pretrained config for `SnypzZz/Llama2-13b-Language-translate` from `transformers`...\n",
      "Loading pretrained config for `mychen76/mistral7b_ocr_to_json_v1` from `transformers`...\n",
      "Loading pretrained config for `alpindale/goliath-120b` from `transformers`...\n",
      "Loading pretrained config for `ise-uiuc/Magicoder-S-DS-6.7B` from `transformers`...\n",
      "Loading pretrained config for `Wanfq/FuseLLM-7B` from `transformers`...\n",
      "Loading pretrained config for `ZySec-AI/ZySec-7B-v1` from `transformers`...\n",
      "Loading pretrained config for `tokyotech-llm/Swallow-MS-7b-v0.1` from `transformers`...\n",
      "Loading pretrained config for `alchemonaut/QuartetAnemoi-70B-t0.0001` from `transformers`...\n",
      "Loading pretrained config for `INSAIT-Institute/BgGPT-7B-Instruct-v0.2` from `transformers`...\n",
      "Loading pretrained config for `facebook/opt-2.7b` from `transformers`...\n",
      "Loading pretrained config for `tiiuae/falcon-7b-instruct` from `transformers`...\n",
      "Loading pretrained config for `mosaicml/mpt-7b-storywriter` from `transformers`...\n",
      "Loading pretrained config for `tiiuae/falcon-40b` from `transformers`...\n",
      "Loading pretrained config for `HuggingFaceM4/idefics-9b-instruct` from `transformers`...\n",
      "Loading pretrained config for `hfl/chinese-alpaca-2-7b` from `transformers`...\n",
      "Loading pretrained config for `codellama/CodeLlama-7b-Python-hf` from `transformers`...\n",
      "Loading pretrained config for `amazon/MistralLite` from `transformers`...\n",
      "Loading pretrained config for `cognitivecomputations/dolphin-2.6-mistral-7b-dpo-laser` from `transformers`...\n",
      "Loading pretrained config for `abacusai/Smaug-34B-v0.1` from `transformers`...\n",
      "Loading pretrained config for `SeaLLMs/SeaLLM-7B-v2` from `transformers`...\n",
      "Loading pretrained config for `Qwen/Qwen1.5-1.8B-Chat` from `transformers`...\n",
      "Loading pretrained config for `Qwen/Qwen1.5-4B-Chat` from `transformers`...\n",
      "Loading pretrained config for `wolfram/miqu-1-120b` from `transformers`...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 730/730 [00:00<00:00, 177kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained config for `ibivibiv/alpaca-dragon-72b-v1` from `transformers`...\n"
     ]
    }
   ],
   "source": [
    "response = get_tgi_models_and_parse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 253.25ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29353"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset \n",
    "\n",
    "ds = Dataset.from_list(response)\n",
    "\n",
    "ds.to_csv(\"tgi_models.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = get_emb_models_and_parse(limit=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 522.78ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5575"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset \n",
    "\n",
    "emb_ds = Dataset.from_list(embedding)\n",
    "\n",
    "emb_ds.to_csv(\"emb_models.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
